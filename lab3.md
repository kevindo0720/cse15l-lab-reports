# LAB 3 REPORT

In this lab, I will show you the alternative terminal commands to `less`.

Through the use of phoenixNAP's documentation, I was able to obtain 4 other terminal command alternatives, including: `less -E`, `less -N`, `less -s`, and `less -p[pattern]`.

Here is an the link to the [documentation to phoenixNAP that I used](https://phoenixnap.com/kb/less-command-in-linux): 


# GENERAL DESCRIPTION OF LESS AND HOW IT WORKS
less is a command that shows a file's contents one screen at a time. When you run `less` on a file, you will enter a screen with juse the content of that file. To exit the current screen, you have to press `q`

# 1) Less -E
`less -E` is a command line that exits the less screen when reaching the end of the screen

In example 1, I cd into the Fletcher's directory in the non-ficton folder and use `Less -E` on chapter 1

**Example 1:**
```
kevindo@Kevins-MacBook-Pro-2 Fletcher % less -E ch1.txt

In the Western experience with evil, we choose repeatedly to put our faith in law and the legal culture to redeem ourselves from sin. Over and over again, we find states indulging in total war, terror, genocide, and the mass killing of their own people, and then turning to the legal culture in the hope that they can atone for the iniquity and live once again as a civilized nation. This view—that the law shall make us clean—should give us pause. Faith in the law has not been an unqualified virtue in the Christian West. One might expect individuals influenced by Jesus’s Sermon on the Mount to turn first to love and charity as the means of atonement. But nations—organized, organic societies—must take a different path. A nation must proceed collectively to find redemption.
I write in this chapter of religious ideas and their value in understanding our legal experience. This, admittedly, is an unusual take in our rigorously secular academic world. The American university world has distanced itself from the sensibilities of ordinary Americans who take the Bible seriously as a source of wisdom and who live their lives with devotion to values of faith and redemption. In this interpretation of law as the path to national redemption, I seek to find a middle way between Jewish and Christian thinking. There is no doubt that the nations whose struggles I describe—France, Germany, and the United States—think of themselves as Christian nations. Yet, the very idea of redemption of the entire nation through law resonates more with the older tradition of the Jewish national mission under the Torah revealed at Mount Sinai. My account seeks to unite the divergent strains of all religions that trace their roots to the original idea in Exodus of a nation living under God and under law.
To understand the phenomenon of communal redemption, we must turn to the Bible as our source. The model of the Hebrews’ deliverance from servitude and their ensuing acceptance of God’s law at Mount Sinai have repeatedly appealed to dominant powers of the West and often to opposite sides of the same conflict. In the rhetoric of the abolitionists, slavery in the United States made the country into “a House of Bondage.” Both blacks and whites identified with the same story of liberation from this domain of oppression. Nat Turner thought he was recreating the biblical story when he led a slave revolt in 1831. The slaves whom Harriet Tubman led to freedom in the North called her Moses. Abraham Lincoln readily saw himself in the image of Moses leading his people out of bondage into the realm of freedom.
The Hebrews fled Egypt in order, eventually, to accept the law revealed at Mount Sinai: delivery from servitude requires more than violent revolt. The message of Exodus is not simply liberation from slavery but the domesticating of violent sensibilities under the rule of law. Jews celebrate this submission to God’s law in the holiday of Shevuot, which commemorates the revelation of the Torah at Mount Sinai and is celebrated fifty days after the night of the Exodus. Christians have reinterpreted this event as the descent of the Holy Spirit, celebrated in the analogous spring holiday of Pentecost.
The idea that freedom exists only under law is often understood as a Central European or German approach to the individual in society. Americans tend to subscribe rather to the myth of a Lockian state of nature, where individuals exist prior to the organization of society under a social contract. The Declaration of Independence relies heavily on the principle that the “consent of the governed” is indispensable to the legitimacy of government. Yet, in actual American practice, the law—particularly constitutional law—serves the same function of sanctifying the social order as it does in the European experience. Before turning to the details of the American appeal to law after the surrender at Appomattox Courthouse in April 1865, let us examine first two significant European efforts to domesticate tendencies toward violence under the rule of law.


Redemption by Law in 
France and Germany

Think first about the way in which the French sought repose from post-revolutionary terror in their Code civil. The country passed through fifteen years of regicide, terror, and mass executions. Amidst voices clamoring for stability and security, Napoleon staged his coup d’état in late 1799. High on his agenda was revamping the legal system. In 1804, he charged a group of lawyers with the task of drafting a new civil code in language accessible to ordinary people. The committee produced the elegant Code civil, now a mainstay of French culture and a model for civil codification all over the world. The language is so refined that the novelist Henri Stendhal reportedly reviewed the style of ten code provisions every night before retiring. Today, when the Francophones in Quebec preach the distinctiveness of their culture, they never fail to mention their Code civil, modeled after Napoleon’s effort to use the law as the means of restoring civilized order to France.
The Code civil has proved to be remarkably durable in French culture. Constitutions have come and gone and the French have endured recurrent changes of regime, including communes, dictatorships, and five distinct republics. Yet, through all this, the civil code has survived. It is the cultural monument that unites the French across history.
In its substantive content, the Code civil is strongly identified with the achievements of the 1789 Revolution against the ancien regime. The code sweeps away the vestiges of feudal influence in the law of property and in the law of evidence and proclaims a liberal legal order. The end of feudalism in the law of property meant that a single concept of ownership would replace the ancient system of embedded estates. The implication was that all land would be freely alienable, without being burdened by the residual control of lords higher in the feudal chain. The code thus provides the legal foundation for a market economy. The end of feudalism in the field of evidence means that the testimony of a nobleman is no longer worth more than the oath of a peasant. Thus the code institutionalizes the égalité of all citizens, as promised in the slogan of the Revolution.
Standing for these liberal values, incorporating the messages of revolution, and surviving all changes of political regimes, the Code civil functions like a constitution for the French. It is the bedrock of the legal culture. In their code, the French have found an enduring symbol of the rule of law, a conviction that the language, concepts, and rules of the legal order can hold back the impulses toward violence, terror, and reciprocal vengeance. Faith in the code has redeemed the nation from the nightmare of the guillotine.
The metaphor of redemption should not pass our lips lightly. In its original meaning, it has legal connotations; something on loan gets returned to its owner. The older Jewish law of homicide relied on the metaphor of the Goel haDam, “the redeemer of blood” to refer to the victim’s next-of-kin who, under certain circumstances, could pursue the murderer and kill him. David Daube has interpreted this practice against the background assumption that at the time of a natural death, the life force—symbolized by blood—always returns to God.1 If the death occurs at the hand of another, the manslayer unnaturally acquires control over the victim’s “blood.” The Goel haDam, the redeemer-of-blood, executes the manslayer in order to release the victim’s blood, thus enabling it to return to its divine source. The notion that our life force belongs to God accounts for the views of virtually all secular liberal systems that no one can validly consent to his or her own killing at the hand of another.
It is tempting to extend this idea and to think of all humanity as enjoying a temporary privilege of life on earth. God somehow will redeem all of us at the end of history. In fact, the Jewish view, as it has evolved and matured, seems to have avoided this universalization of the idea that individual life stems from God. As the idea developed, the agent of redemption would be the Messiah, who would bring a reign of peace and harmony to life on earth. The redemption occurs in life as we know it. Orthodox Jewish culture takes the observance of God’s commandments, living under the rule of revealed law as interpreted by the rabbis, as the way to hasten the Messiah’s reign of harmony and order. The law, then, becomes the path toward redemption. Until the Prince of Peace comes to “fulfill the law,” or until the Apocalypse at the end of days, the secular law of the nation is the only means we have to work toward the perfection of life on earth.
The place of “blood” in the religious tradition of redemption proves to be subtle and problematic. There are some strains in the Jewish tradition that link the letting of blood with returning the soul to God. The “redeemer of blood” reminds us of that connection, as does the popular view that the founding of Israel stood in some kind of organic relationship with the Holocaust. The connection between blood and salvation becomes much stronger, however, in the Christian interpretation of its Jewish legacy. The theme of blood spilling from the body becomes powerful in the crucifixion and reaches its apotheosis in the faith that a great battle, an Apocalypse, must precede the Second Coming of the Messiah. The spilling of blood in a great battle is understood instinctively as the suffering that must precede redemption. As John Brown was led to the gallows on the eve of the Civil War, having unsuccessfully sought to stimulate a slave revolt, he handed one of his guards a note, “I John Brown am now quite certain that the crimes of this guilty land will never be purged away but with blood.”2
But blood alone does not save a nation from its sins. The argument here is that indulgence in evil—slavery, mass killing, persecution—must first issue in the suffering of the people. To overcome their sense of self-inflicted brutality, they turn to the law as the path of secular redemption. They search for stability after having succumbed to their baser instincts. The law provides a source of hope that the civil order can resist the recurrent slippage into violence and brutality. The important point is that the rule of law—not charity, not prayer, not animal sacrifice—should provide the means of secular redemption.
For nations as a whole to seek redemption, they must find a discipline that operates on them as a group, as a community. Individual acts of devotion will not suffice. Needed is the discipline represented by the law—the expression of communal cooperation, par excellence. The compromises and obligations of life under the law hardly makes sense to individuals standing alone, preoccupied by their own values and their own needs. The law redeems not the individual but the community or the nation as a whole.3
This view of the relationship between law and redemption finds expression in the Hebrew Bible, the Old Testament. It continues to inspire the law-based thinking of Judaism, Islam, the Catholic Church, and some Protestant theologians. The law given at Sinai, the law embedded in the covenant, is not the expression of individual aspiration but only of collective obligation. Seeking redemption or salvation through the church or through faith provides a way of cleansing ourselves of sin and, as it were, perfecting our individual creation.
Legal cultures, too, must seek to perfect themselves. They cannot exist simply as the product of will. When legal cultures lose sight of their natural end of bringing a reign of justice and harmony to human affairs, they decline into corruption and the arbitrariness of power. The German philosopher Gustav Radbruch defined the ideal of Law as the practice of establishing rules in the pursuit of justice.4 Communal life seeks, through law, to perfect itself. This secular idea parallels the eschatological aim of perfecting the creation of the world under God’s reign.
Seeking redemption under the law cannot simply be a desire for one’s parochial values to triumph in the courts. It matters which values are in play. And it matters how these values are debated in the legal culture. Debate about legal issues must be open and robust, and the very process of legal argument must communicate respect for the opposition. At the end of a legal argument, both sides must have the sense that they have been listened to, and that the dignity of the losing party is affirmed in the process of decision. Here, as well, we have much to learn from the model provided by the Jewish tradition of Talmudic debate. When a rabbi questioned how two of the greatest sages, Rabbis Hillel and Shammai, could persistently disagree, the response was: “These and these are the words of the living God.” Although Rabbi Hillel’s views are generally followed, Rabbi Shammai is treated, in defeat, with the greatest respect.
It is not surprising that when the established authority’s respect for the political opposition is debased, the legal culture invariably suffers. This is most noticeably clear in dictatorial societies where legal debate is reduced to little more than efforts to placate the powers that be. Although the National Socialists purported to rely on legal forms and administrative regularity, their contempt for free and mutually respectful discourse led to a corruption of the legal culture. The Nazis’ conception of law fluctuated between two unpalatable extremes. Sometimes the slogan was that law was what Hitler wanted and commanded (Recht is das, was der Führer will). At other times, utility to the German people was the ultimate source of legitimacy (Recht is das, was dem Volke nutzt).5 The National Socialist Party’s manipulation of these slogans and their observance of legal forms served only to bring the culture to a deeper level of corruption.
It is an extraordinary feature of postwar German culture that a new generation of jurists managed to save, to redeem, their concept of law from its racist and Nazi associations. In the wake of their unforgettable crimes against humanity, the West Germans, too, sought redemption in the rule of law, in the Rechtsstaat that they have cultivated along with economic prosperity. Living by the law, and seeking justice within the law, redeems the humanistic side of German culture. It has suppressed the romantic will to break all restraints for the sake of glory in power.
The Germans, too, have a civil code that has united them, since 1900, through the transitions from Bismarck, to Weimar, to the Third Reich, to the present. Yet, under the National Socialists, the code, which contains the provisions on family law, became tainted with notions of racial purity. Jews and Aryans could not marry. Of course, this stain disappeared in the postwar reform, but the memory remains of a corrupted civil code. Not surprisingly, then, Germans have sought redemption by promoting both a new constitution, enacted in 1949, and the rule of law in a united Europe. More than any country seeking redemption under law, the Germans identified their new constitution, the Grundgesetz, as the focal point of state authority. The sanctity of the constitution—and not the personal head of state—became the interest protected under the reformed law of treason. When West Germans felt their infant postwar republic endangered by Communist subversion, they appointed an agency to protect the integrity of the government. The announced aim of the agency was to protect the constitution (Verfassungsschutz).
The preamble of this charter, called the Basic Law (Grundgesetz), repeatedly reminds Germans of the imperative to atone for the sins of the past:

Conscious of its responsibility before God and humanity, possessed of the will to serve the peace of the world as an equal member of a United Europe, the German nation [Volk] commits itself, by virtue of its inherent constitution-making authority, to the following Basic Law.6

No other constitution, so far as I know, stresses its sense of “responsibility” and declares as one of its primary purposes “to serve the peace of the world.” These gestures recall the descent of the German nation into the evils of aggressive war and crimes against humanity.
The first article of the Basic Law invokes the humanistic Kantian underpinnings of German culture: “Human dignity is inviolable. All state power is obligated to protect it and respect it.” This provision provides the backdrop for interpreting all the basic rights guaranteed under the constitution. The protection of human dignity is the fundamental value suffusing the entire legal order. The highest virtue of the postwar German constitutional order, then, was precisely the greatest casualty of the Nazi regime. The path to redemption lay in reclaiming the liberal and humanistic values most systematically violated in their darkest hour. The point is carried forward in the second article: “Everyone has the right to flourishing of his or her personality. . . . Everyone has the right to life.”
These are provisions that enabled Germans to redefine their identities. They would no longer be the people devoted to the Volk above all. They would become the nation of human dignity that served the cause of human flourishing and the sanctity of human life. For the postwar Germans, then, the law, and particularly the Basic Law became the means for suppressing evil impulses and returning to the promises of an earlier national self. This is what redemption means in a secular legal world.
The redemptive impulse leads national courts to place an emphasis on values that resonate against past sins. The German Constitutional Court has made a number of controversial decisions that make sense primarily as efforts to resolve the burden of memory. The court decided to uphold a law abolishing the twenty-year statute of limitations for concentration camp murders.7 It invoked the constitutional “right to life” to strike down a liberal abortion law that permitted abortion on demand in the first trimester.8 And, more recently, the court rejected an East German statutory justification for border guards who shot at their own citizens trying to flee the country for the West.9 All of these decisions brought to the fore fundamental values of protecting life and punishing those with contempt for life. Yet, the particular German emphasis on these values would probably not appeal in the same measure to other European courts.
The Germans themselves have coined a unique, hard-to-translate phrase to describe the controversies that have driven their system of justice for the last fifty years. They call it Bewältigung der Vergangenheit—“overcoming” or “coming to grips with” the past. Settling accounts with the past provides a critical perspective on the process of redemption from evil. We cannot avoid the past, for we are all prisoners of it. In real life, we cannot reenact the forty years of wandering in the desert that the Hebrews had to endure before they could shake off their ingrained ways and a new generation could seek redemption under the law. In the world of practical politics, we must act now, and criminal punishment often provides the mechanism for distancing ourselves from the past so that we can start anew.


Civil War as the Path 
to Redemption

As France and Germany had their experiences of seeking redemption after reigns of terror, Americans, too, indulged in the mammoth bloodletting on the killing fields of the Civil War. When Lincoln sought to resupply Fort Sumter in Charleston harbor, and General Beauregard chose in response to fire on the federal fort, the long-simmering feud between North and South bled into brothers’ killing each other at close range. They fired their canons on Fort Sumter, they fixed their bayonets at Little Round Top, they lobbed shells onto Vicksburg until troops could seize the forts reigning over the Mississippi, they burned down Atlanta, and under William Tecumseh Sherman they scorched the earth on their march to the sea. The blue and the gray fell everywhere. And they were not sure why. They only had abstract ideas in their heads—some died for the Union, others for their separate nation. Over six hundred thousand lives stained the ground, more than all the former and subsequent American wars put together.
Having barely won reelection midway in this slaughter, Abraham Lincoln could only say of the reign of terror, “Woe unto the world because of offences!” We had descended into the bloodiest war of our history without clear purposes or any understanding of how it might end. “For it must needs be that offences come; but woe to that man by whom the offence cometh!” The self-inflicted pogrom is seen as a “woe” and a “scourge” inflicted for the terrible “offence” of slavery. Lincoln’s second inaugural address prayed for redemption. The nation had bled its sins onto its own soil and craved a rebirth of American civilization.
The survivors turned to law. One year into the war, after a string of Union defeats, Lincoln learned that the old Union could not possibly survive. “A new one had to be embraced.”10 And the new Union would have to be based on a new constitutional order. A nation of free Americans, including emancipated slaves, would bear responsibility for rebuilding the United States on the basis of a constitution acceptable to all. Formally speaking, the original charter of 1787 would remain in place, but it would be so radically transformed that it would stand to the ancien United States as the Code civil related to the French feudal order or, as any redeemed legal culture compares to the brutality and chaos that precedes it.
The American hope for a new beginning lay in the Reconstruction Amendments—the Thirteenth, Fourteenth, and Fifteenth—all enacted in quest of a new definition of freedom and equality under the law. The first clause of the Fourteenth Amendment specified who would be a member of the new polity: “All persons born or naturalized in the United States, and subject to the jurisdiction thereof, are citizens of the United States. . . .” With a single stroke the new constitution erased the effects of one of the worst blemishes in American constitutional history—the Dred Scott decision of 1857, which held that persons of African descent could never become citizens of the United States. In the new United States, there would be no discrimination based on blood. The only question that mattered was whether you were born within the polity and whether you were therefore likely to come to maturity with the language and consciousness of American culture.
With just boundaries of the new nation-state properly defined, the highest order of business was to define the basic rights of its citizens. The structure of these rights follows the pattern established in the Declaration of Independence: life, liberty, and the pursuit of happiness. Yet, there was a new recognition that the inalienable rights of all Americans were now to be realized not in the state of nature but under the rule of law. The naturalistic “pursuit of happiness,” celebrated in the Declaration, gives way to the quintessential creature of the law’s definition—property. Yet, the basic rights of life, liberty, and property are inalienable without being absolute. The ideal must be adapted to the practical demands of competing claims. The legal system would have to decide when individuals could fairly be deprived of liberty or property or even of life; thus, the coining of the famous and influential clause of the American Constitution, namely that no “State [shall] deprive any person of life, liberty, or Property, without due Process of law.” The law would define the content and the limits of the inalienable rights celebrated in the Declaration of Independence.
Also, for the first time, the law would define duties incumbent on the states. The individual state governments must not only guarantee due process for all persons within their jurisdiction, they must also secure “the equal protection of the laws” for all to whom their power extends. True, the original Constitution places some limits on the legislative competence of the states. They must defer to the supremacy of federal law and recognize the privileges and immunities of the citizens of all other states.11 And there were specific restrictions: They could not enact bills of attainder, ex-post facto laws, or any “law impairing the obligation of contracts.”12 In the postbellum constitutional order, however, the states acquired a pervasive duty to treat their residents—those subject to their jurisdiction—decently.
This was a revolutionary change. The states were no longer the autonomous sovereigns that they thought they were when they claimed the right of secession. They were now, in fact, servants of their people. Governments existed to guarantee due process and equal justice for all. The local law was no longer simply a creature of the states. The states themselves were enmeshed in the law and subordinate to it.
In addition to embedding the states in the rule of law, the new constitutional order embarked on an affirmative program to ensure equality among those citizens subject to the jurisdiction of the United States. The heart of the new consensus is that the federal government, victorious in warfare, must continue its aggressive intervention in the lives of its citizens. It must protect the weak against the risk that they would slip into states of subordination resembling the past from which they sought to escape. According to the Thirteenth Amendment, there could never again be relationships of slavery or involuntary servitude in the United States. The federal government would have to be ever watchful to insure that this kind of slippage would never occur in the private relationships among citizens. Furthermore, under the “equal protection clause,” the states must recognize and promote the equality of those subject to their jurisdiction. To round out the commitment to equality, according to the Fifteenth Amendment ratified in 1870, the states could no longer deny voting rights to citizens on the grounds of their race, color, or previous condition of servitude.
These objectives and guarantees are insufficient in themselves to create a constitution, a framework of government. One needs, in addition, a definition of legislative empowerment that would enable the federal government to realize its commitments. This definition is laid down in all three of the postbellum amendments. All three grant the power to Congress to enforce the basic framework “with appropriate legislation.” True, the new Congress takes as a given many of the provisions of the original Constitution. The new order inherits an operating Congress, Executive, and Judiciary. They would be recast in new functions, but the forms remained the same.
The argument, then, is that the three Reconstruction Amendments enacted a second American constitution. The terms of this constitution, as culled from the amendments—with some rearrangement and leaving out historically specific clauses—can be stated in a few words:

The Second American Constitution
§1. All persons born or naturalized in the United States, and subject to the jurisdiction thereof, are citizens of the United States and of the State wherein they reside.
§2. No State shall make or enforce any law which shall abridge the privileges or immunities of citizens of the United States.
§3. No State shall deprive any person of life, liberty, or property, without due process of law.
§4. No State shall deny to any person within its jurisdiction the equal protection of the laws. 
§5. Neither slavery nor involuntary servitude, except as a punishment for crime whereof the party shall have been duly convicted, shall exist within the United States.
§6. The right of citizens of the United States to vote shall not be denied or abridged by the United States or by any State on account of race, color, or previous condition of servitude.
§7. The Congress shall have power to enforce the foregoing provisions by appropriate legislation.

These seven propositions summarize the enduring content of the Reconstruction Amendments.13 The key provisions of these amendments define political membership, articulate basic rights, and provide an ambit of legislative competence. So reformed, the American system of government would be able to protect individual rights as well as promote the equality of all persons who survived the war. Of course, we must assume a set of institutions—a Congress, an Executive, and a Judiciary—that will continue to function according to the terms of their initial creation.
Still, there is something missing in this filtering off of the three Reconstruction Amendments and calling them a separate constitution. The missing factor is the consciousness of setting forth a new framework of government, a structure based on values fundamentally different from those that went before. To find that consciousness, we need to turn, I wish to argue, to the critical message of the Civil War, the address that would generate a new normative world in which to make sense of the epic war that consumed America from the firing on Fort Sumter to the surrender at Appomattox. The new Nomos, the new framework of values that necessitated a new constitution, comes forth in one of the great prayers of the American civil religion, the Gettysburg Address. It is worth recalling some of the enduring phrases of this civil prayer, the incantations that reverberated in American consciousness:

Four score and seven years ago our fathers brought forth on this continent a new nation. . . .
[This nation was] conceived in liberty and dedicated to the proposition that all men are created equal.
From these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion.
We resolve that these dead shall not have died in vain, that this nation, under God, shall have a new birth of freedom. . . .
Government of the people, by the people, for the people shall not perish from the earth.
In the ensuing chapters, we will look at these words and the entire address in greater detail. For now, I wish to make the unusual claim that these revered words serve as the preamble for the constitutional order that emerged from the unification of the nation. They are a preamble in much the same sense that the language beginning “Conscious of our responsibility before God and humanity” provides the organizing principle of the new German constitution or the following words echo in memory as the convening of the Philadelphia Constitution:

We the people of the United States, in order to form a more perfect Union, establish justice, insure domestic Tranquility, provide for the common defense, promote the general Welfare, and secure the Blessings of Liberty to ourselves and our Posterity, do ordain and establish this Constitution for the United States of America.

Constitutional preambles speak in prophecy. They set forth a vision of the future—for the broad purposes of the national charter that they introduce. And, most important, they define who the people are who share in the constitutional vision. The original preamble in the Philadelphia version stressed the position of “We the People” as the enactors of the Constitution. For Lincoln, the body politic expressing itself in the new constitution included the prior generations who “four score and seven years ago” adopted, with great courage, that proposition of equality that gave birth to the American nation. Those represented in the new order included the dead at Gettysburg and at all the battlefields of the war who, if the new order is realized, “shall not have died in vain.” And, furthermore, because he avoided all partisan references in his address, he clearly meant to articulate a conception of the nation that included the South as well as the North, black as well as white. Ultimately, the beneficiaries of the new order would be the future generations of the nation, those who would flourish under “a new birth of freedom.”
To say that the Gettysburg Address provides the preamble to a new constitutional order is, to say the least, a bold claim. When Lincoln took the train up to Gettysburg in November 1863, he had in mind only to comfort the mourners of those who died in the fierce four-day battle in early July. The bodies were being pulled together from the battlefield and spared further decay. The soil was turned and the dead laid to rest. The battle had turned the tide of the war—just barely, mind you—and it was time that the president began to articulate the meaning of the long suffering that culminated in the gruesome hand-to-hand fighting in the Gettysburg fields.
At the ceremony dedicating the Gettysburg cemetery, Lincoln was designated the second speaker. The renowned orator Edward Everett spoke for two hours before the president mounted the podium. He had a written text with him that amounted to about 268 words.14 Perhaps Everett prepared the audience to absorb the poignancy of Lincoln’s message. Perhaps the very brevity of Lincoln’s words lent them additional power. The impact of the address was felt not only by the mourners gathered at the new cemetery but by an entire country yearning for a sense of meaning in the bloodshed.
True, the Gettysburg Address was not legally binding, but preambles are never meant to have the status of positive law. They are designed to explain why it is necessary for the government to bind itself to certain objectives. Lincoln’s preamble, accepted in the hearts of the nation, explains the meaning of the war and provides a guide to the building of a constitutional order based on nationhood, equality, and democracy. The setting of clear goals in inspiring language—this is all one can expect of a constitutional preamble.
This constitutional order stands in radical contrast to the Constitution drafted in Philadelphia and amended by the Bill of Rights in 1791. It defines membership in the American nation, it brings the principle of equality to the fore, and it initiates the process of extending the franchise to virtually all adult citizens. The original Constitution did none of these things. It slighted the problems of nationality and citizenship, it sidestepped the problem of equality, and it minimized the significance of popular democracy.


The Irrelevance of 
Original Intent

At the outset, I should be clear about the claims I am not making and the methods I am not using. Above all, I am not making an argument about the “original intent” that lay behind the Reconstruction Amendments. Nothing strikes me as intellectually and morally more impoverished than the current trend in constitutional scholarship to believe that the wishes, desires, and intentions of the founders should determine the content of our Constitution. There are two major hurdles that the advocates of this method have never negotiated. First, we need an argument about whose wishes, desires, and intentions really matter. If we think we are bound by a certain take on the world that prevailed in 1787, 1791, or 1868, then we should decide whose sentiments matter. Should we look to the people who wrote the document, to the majority who voted for it, to the states who ratified it, or to the “people” as a whole for whom these various democratic agents acted? Among all these possible sources of “original intent,” there was intense conflict. I would imagine that even those who actually voted for and against various drafts suffered from doubt and changing sentiments. But even if each person voting had a concrete intention to support every sentence he or she endorsed, there is no coherent way of finding a common denominator among their divergent positions. A single intent cannot unify the inevitable cacophony of desires that stand behind every piece of legislation. But let us suppose there was a single intent of the group. We then encounter a more basic question: Why should we care what the founders actually thought?
The best political theory to support the relevance of original intent would be to think of the lawgiver as something like a military commander.15 The commander wants us to do something, and has used the language of the law to move us toward action. We should try to figure out what these purposes are and execute them. And if we don’t? Well, the commander cannot really punish us, but somehow we would be breaking faith with the framers if we don’t act with the appropriate subservience or at least act as though we were submissive to the original intent of the founders. This, I regret to say, is the best reconstruction I can offer for a view that never seems to get articulated; namely, why we should pay so much attention to the wishes and desires of the agents who bequeathed to us the words we live by.
In great historical moments of law making as well as literature, writers choose words that resonate far beyond their original context. When the representatives of the colonies “pledged their sacred honor” in July 1776 to a document that included the words “All men are created equal,” they may merely have intended to stress the equality of all “collective” peoples: the new Americans had as much right to choose their form of government as did the British. They also could have had the limited purpose of arguing that they were of the same moral status as King George III. If all men are created equal, then no one of them can claim to be anointed as ruler by divine right. The only source of legitimacy, as the Declaration argues, is the “consent of the governed.” Whatever their intentions as individuals or as a group may have been, their words had lasting significance. They bequeathed a great maxim to the American people—a maxim that would in due course serve as the battle cry of emancipation.
When the drafters and ratifiers of the Fourteenth Amendment adopted a commitment to equality under the law, they did not think particularly about whether they wanted to bring about integrated schools. Yet, a vast literature has grown up around the question of whether the “original intent” of the Fourteenth Amendment was to integrate the schools—an event that the Court did not mandate until 1954 in Brown v Board of Education.16 The dispute seems to be entirely irrelevant.17 The complex body of national and state legislators who drafted, passed, and ratified the Fourteenth Amendment did not think about a single system of education for blacks and whites. There were too many other issues on their minds. We cannot attribute to them an intention to have all Americans study together in the same classroom, nor can we burden their memory with a commitment to keep black and white forever apart.
Those who frame constitutions and constitutional amendments obviously have some purpose in mind, but the purposes are typically abstract. If they want to bring about equality among all Americans, they do not want to be bothered with working out precisely what equality means at each stage of historical evolution. If you had asked them whether, ninety years later, the schools should be desegregated, they would have been nonplussed by the question. “Well, that is the reason we have courts,” would have been the typical reply. The Fourteenth Amendment established an ideal, it affirmed an idea that has roots in the Declaration of Independence. The drafters implicitly endorsed the principle that all men are created equal and because they are created equal, they are entitled to equal treatment before the law. What this language should mean in practice was not their concern. Together with scholars who reflect on the ideas behind the law, the courts assume responsibility for the proper interpretation of the language that constitutes a shared heritage of government principles.
I never cease to be amazed that legal scholars, particularly in the United States, continue to be confused about the relevance of the framers’ original intent. Secular legal systems could not possibly be more demanding, more deferential to authority, than religious cultures that believe that their binding legal principles were declared by God. Yet, a story from the Talmud beautifully illustrates the folly of invoking original intent in a dispute about the meaning of God’s commandments. A group of rabbis were engaged in a debate about whether a particular earthenware oven was kosher or not. One of them, Rabbi Eliezer, said no; the other rabbis said yes. Rabbi Eliezer proceeded to invoke a variety of fantastic signs to support his view: at his command, a carob tree was uprooted and flew across the field, a stream flowed upstream, and the walls started to collapse before they were halted. The rabbis were not impressed by these signs. Then Rabbi Eliezer, desperate and alone, invoked the argument of original intent: “If I am right, let heaven be the proof.” A heavenly voice then proclaimed: “How dare you oppose Rabbi Eliezer, whose views are everywhere the law.” Rabbi Joshua arose and quoted Deuteronomy: “It is not in Heaven.” Rabbi Jeremiah explained the reference: Ever since the Torah was given at Mount Sinai, “we pay no attention to heavenly voices, for God already wrote in the Torah at Mount Sinai.”18 The point is that once the language is released and given to jurists to fashion to the needs of their time, the task of lawgivers is finished. Their intentions and desires cannot rule—either from the grave or from heaven.
The intention of those who framed the Reconstruction Amendments should, therefore, not control their interpretation today. But what about the intention of Abraham Lincoln, when he mounted the podium on November 19, 1863? There are some who will say that if Lincoln did not intend specifically to articulate the preamble to a new constitution, then the words spoken at Gettysburg could not possibly be, as I claim, the preamble to the postbellum constitution. If Roosevelt did not intend to amend the Constitution with his court-packing plan, then the resulting changes in Supreme Court attitudes could not constitute a de facto amendment, a radical transformation of American law.
Here we take a page from British constitutional history to understand how a practice can be become part of the accumulated historical constitution without this being the purpose of those who initiated the practice. The British Constitution remains, as is well known, famously unwritten. Customary rules determine the role of the Crown in a system that has evolved as a constitutional monarchy. Only the accepted practice of generations prescribes that the queen must sign legislation for it to be binding as law or that the queen may intervene, under certain circumstances, to break a party deadlock and select a nominee for prime minister.19 In all systems of customary law, the relevant perspective is not that of those who first engage in the practice but rather of those who witness the pattern of the past and adopt it as binding on themselves. So it is with the Gettysburg Address. The right question is not what Lincoln intended, but rather what the words meant to those who looked to them as the explanation of the war and as a charter for freedom and equality for all Americans. If the address had been ignored, it would not have mattered what Lincoln intended. But because these 268 words20 were adopted into the civil religion of the United States—the secular meditation on who we were and what we were about—their life after formal recitation by the president determines their constitutional status. They are the preamble to the constitutional order because we came to understand them as nearly sacred. And although we did not until now think of this secular prayer as the preamble to a new order of nationhood, equality, and democracy, that is what they became.
These words are, in fact, better known in the United States than the preamble to the first Constitution. Schoolchildren routinely recite them and thereby imbibe the intuition that these words defined America after the Civil War. Yet, because we know these resonant phrases, we rarely stop to listen and ponder the meaning of each well-crafted line. Let us now put ourselves among the crowd of mourners at Gettysburg. Let us transport ourselves back into the frame of mind of those suffering losses, those looking for the meaning of brothers slaughtering brothers.

Four score and seven years ago our fathers brought forth on this continent a new nation, conceived in liberty and dedicated to the proposition that all men are created equal. Now we are engaged in a great Civil War, testing whether that nation or any nation so conceived and so dedicated can long endure. We are met on a great battlefield of that war. We have come to dedicate a portion of that field as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this. But in a larger sense, we cannot dedicate—we cannot consecrate—we cannot hallow this ground. The brave men, living and dead, who struggled here have consecrated it far above our poor power to add or detract. The world will little note nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us—that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion—that we here highly resolve that these dead shall not have died in vain, that this nation, under God, shall have a new birth of freedom, and that government of the people, by the people, for the people shall not perish from the earth.
```
After this, it automatically exits the screen, and returns to the terminal without me manually pressing `q` on my keyboard


**Example 2:**
Similarly, in example 2, I used `less -E` to print out chapter 5 in its entirety and exit it immediately once I reach the end.

```
kevindo@Kevins-MacBook-Pro-2 Fletcher % less -E ch5.txt


The genius of the Gettysburg Address is that it took the words of the Declaration of Independence and found in them a crystallization of a meaning suitable for the refounding of American democracy. In 1776, the idea that “all men are created equal—for all purposes” had no precedent in the declarations of political leaders. Even the great French Declaration of the Rights of Man, issued thirteen years after the French Revolution, preached a more limited version of equality—“All men are born and remain equal under the law.”1 In its original context, the famous five words “all men are created equal” had a limited function. They undermined the pretension of King George III to rule under the divine right of kings. If all men were of equal stature under God, then no one could claim to have been anointed as ruler by supernatural authority. At the same time, however, the famous maxim could also be understood as referring to “men” as collective entities: “all peoples have equal status.” It was not particularly novel to argue that all nations, all states, had an equal claim to govern themselves. The principle of national self-determination, urged so adamantly in the twentieth century, derives from the same source: every nation is entitled to preserve its own culture, cultivate its language, and express itself as a subject of the international community. International law is based on the idea that nations, anchored in the form of states, enter into legal relationships. The states in which nations are embodied enjoy legal personalities. They incur debts and, significantly, these debts are not extinguished by revolutionary changes of government. The forms of the state come and go, and the nation endures through it all. It is no wonder, therefore, that the Declaration of Independence would assert that the American people were equally entitled, with all other nations, to determine their form of government.
These two senses of the famous “all men are created equal” capture the ambiguous quality of the American revolt against the British. It was both a revolutionary and an anticolonial war of independence. The revolutionary spirit was captured in the categorical rejection of monarchy. The anticolonial thrust appears in the assertion of the Americans’ equal claim to rule by “consent of the governed.”
More far-reaching than both of these original meanings, however, is the individualist interpretation: All human beings are of equal dignity. They are created equal and remain equal in the eyes of their Creator. There can be no foundation, therefore, for the claim that whites are superior to blacks or that men should count more than women. Of course, many framers of the Declaration were slave owners and most, if not all of them, were patriarchal heads of households. Yet, they bequeathed to the world a rhetorical phrase that was pregnant with meaning deeper than many of them may have intended. This deeper meaning lay, embedded in the text, ready to come alive for the first time as their Declaration became the sacred text of the American abolitionist movement.
Legal texts often bear one meaning on their surface and a higher meaning that requires faith and personal investment beyond the surface meaning. A good example is the commandment in the Decalogue prohibiting homicide. Allow me a short digression on the commandment against killing to illustrate the phenomenon of a text that carries one meaning on its surface and a more radical meaning beneath.
The Hebrew expression in the Sixth Commandment, lo tirtsach, is generally read: Thou shall not commit murder. The term “murder” implies a prohibition only against unjustified killing, implying the permissibility of killing in self-defense. Yet, a survey of the sources in Jewish law reveal that the term also bears the interpretation found in many Christian translations: Thou shall not kill. “Thou shalt not murder” is a rule that we can expect people to follow, but “Thou shalt not kill” hardly lends itself to the same strict enforcement. The morality of not killing becomes an aspiration, a challenge for people to realize in their struggle with imperfection. Whether they can renounce self-defense, as the Mennonites appear to have done, is a matter of personal moral realization. Whether they can extend the prohibition against killing to all living creatures, as some exemplary spiritual leaders have done, depends on their moral evolution. Those who eat meat are not wrongdoers or sinners. They simply have not yet reached the highest point of aspiration. One should respect the Buddha, for respecting all forms of life by not killing, but those who fall short of the Buddha are not subject to blame.
The same contrast can be drawn between the equality of all nations and the equality of all human beings. The equality of nations has become a postulate of the international legal order. There may be debate about which groups of people constitute nations entitled to self-determination and representation in the international community, but the principle seems to be accepted by all. For the community of nations, so recognized, equality—let us, say, with regard to voting rights in the General Assembly of the United Nations—becomes a norm readily enforced.
Not so for the equality of all human beings. First, it is not at all clear what we mean by equality, why we should recognize it in all human beings, and what we should do to realize equality in practice. Even Lincoln did not favor the equality of blacks for all purposes, including social and marital relationships. And even if we think that all children are equal in the sight of God, we might understandably bequeath our property to our own kin. How much equality and the form that it should take remain a matter of constant debate.
As in the case of “not killing,” in the field of granting equality, there is always more that one can do. The minimum is recognizing an equal “right to life, liberty and the pursuit of happiness.” This requires, to be sure, the abolition of slavery. But there arises then the question of equality in the exercise of basic legal rights, like owning property, serving on a jury, and testifying as a witness in court. Some of these basic legal rights of equality did not accrue to women until well into this century. At a further frontier is political equality, namely the right to express opinions, to vote, and to hold office. Further up the scale of equality, we encounter equality of opportunity in economic competition: Every individual should have the right to compete on an equal footing, with equal education and the basic resources required for the market.
At this point in the spectrum, we begin to make the transition from equality of opportunity to equality of outcomes. Everyone should arguably have an equal claim to the world’s resources. The manna of life, in Bruce Ackerman’s apt metaphor, should be distributed equally.2 The accidents of birth prevent us all from having equal talents, but perhaps those born with lesser talents should receive some form of compensation for their deprivation. All other outcomes, as John Rawls argues, would be “arbitrary from a moral point of view.”3 A similar form of compensation might be urged for those who fall short in the unfolding of their lives. Some have bad luck in romance, fail at their creative efforts, suffer the accidental loss of a child. An extreme egalitarian might see an injustice, requiring compensation, in these differential life paths.
We might refer to this layered set of possibilities as the spectrum of equality. As in abstaining from killing, one can cross the initial stage of this spectrum and remain unsure about how far to ascend on the scale. To whatever height one ascends on the spectrum of equality, there should be a strong connection between that perch and the reason for recognizing human equality in the first place. Once again, the analogy with the commandment against killing (or murder) proves instructive. However much one becomes convinced that killing is wrong, one needs a reason for that degree of conviction. In order to renounce self-defense you need a reason, something to the effect that violence only breeds more violence. Or, if you wish to emulate the model of Albert Schweitzer, you must say something like: All living things are the creatures of God, they all deserve to live. This is not to say that your reason must be demonstrably correct, but you need a reason for your commitment for it to make any sense at all.
The abolitionists, too, must have had reasons for believing in equality in a way that both Northern and Southern fellow citizens rejected. Abraham Lincoln, too, followed an inner logic in cultivating the deeper meaning of the Declaration of Independence. And today we must also have grounds for taking human equality seriously as a basic ideal of social and political justice.
Providing these reasons turns out not to be so easy. As a descriptive claim, the thesis “all men are created equal” is obviously false. People differ in every conceivable respect—size, strength, intelligence, musical talent, beauty. But being equal is not equivalent to being the same, identical, or similar. Equality is a curious relationship, and its model is arithmetic relations. Two sides of an equation are stipulated as equal, but this may not be apparent to the untrained eye. For example: 17 x 17 = 289. The two sides of the equation are not identical in notational form but equivalent in numeric value. The suggestion is that all our differences are like notational form. My DNA, my biography, my talents, are certainly not the same as yours, but these differences become superficial in light of the deeper equivalence of moral value. What gives us this deep equality of value?
Some philosophers have tried to analyze human equality by searching for some single factor by virtue of which we are equal. We might all be equal because we can use language and say things like, “I am as good as you are.”4 Utilitarians claim that we are equal because we feel pleasure and pain.5 John Locke argued that we are all equal because we are all the property of God.6 Or as contemporary secular thinkers claim, we are all equal because, in principle, we can act both rationally and reasonably.7 All these arguments suffer from the same objection. Suppose someone could not speak, would he not be equal to other human beings? Suppose she could not feel pleasure or pain, would that put her outside the human community? If he were not rational, would he not be one of us? None of these criteria alone could be an adequate test of equality unless it was accompanied by a theory that explained why that factor, and that factor alone, was sufficient to generate the strong sense of human equality. Of little value, as well, is Locke’s influential argument that we are the property of God. Animals also belong to the same Creator but that does make them equal to humans.
Modern philosophical approaches toward equality all suffer from the same flaw. They are strongly committed, vaguely, to some position on the spectrum, but they offer no reason why they are so intensely committed to this value that has become so powerful in the English-speaking West. Human equality seems to be an unquestioned postulate—one of those truths that we hold to be “self-evident.” And those things that are obvious apparently require no grounding in reasons. In the contemporary liberal culture, equality is one of those values that has become so deeply held that it is neither questioned nor justified.
Given the long history of popular belief in the intrinsic superiority of certain classes of people—men, whites, Christians, Americans—the philosophical belief in equality stands as a critique of commonly held beliefs. It is clear that the popular culture still harbors many biases about some people being intrinsically better, entitled to greater privileges, than others. Yet, the long-range popular trend favors overcoming our biases in favor of a belief in the equality of all humanity. The American Revolution took the first step by abolishing the privileges of the nobly born. The 1787 Constitution prohibits both the states and the federal government from granting “titles of nobility.”8 There was this much equality in the founding, but anchoring the “peculiar institution” of slavery in the Constitution was the great “offence” against equality that could be expiated only on the killing fields of Gettysburg and Antietam.
The postbellum history of the United States has carried the egalitarian message of Gettysburg into the liberation of ever more marginal groups. After the emancipation of blacks, the movement for women’s suffrage gained strength and finally triumphed in 1920, and then in unclear succession came the contemporary efforts toward the equal treatment of homosexuals, “illegitimate” children, the handicapped, and even undocumented aliens.9 The thrust toward inclusion of more and more groups within the inner circle of the equally privileged has been one of the central themes of American life. Yet, even the victory of the Civil War is not yet complete. The badges and vestiges of slavery still haunt the land. The quest for redemption from the original sin of slavery continues in our own time.
Our sensibilities are conditioned by our history. But, however difficult the struggle, we have a history of which we can be proud. We Americans were the first to conceptualize the great maxim of equality and to label it a self-evident truth. No other legal system, so far as I can tell, relies explicitly on the principle that all human beings are created in the image of God. Yet, all modern legal systems and international documents of human rights today subscribe to the principle of equality before the law. Typical of the American influence is the 1789 French Declaration of the Rights of Man, which provides in the second part of Article 6: “The law must be the same for everyone, regardless whether it serves to protect or to punish.”10
Equality before the law is the most limited claim of human equality. This form of equality applies only to fellow nationals and residents subject to the same legal order. More ambitious are the arguments of the philosophers such as Ackerman and Rawls who claim that equality is the first principle of social justice. At the outer reaches of principle, we find the great maxim invoked in the Gettysburg Address: All human beings are equal in the sight of God.
Let us limit our thinking, for the time being, to the most modest claim—that all individuals, black and white, men and women, gay and straight, born in wedlock and out of wedlock, should be treated equally under the law. We did not recognize this principle in the 1787 Constitution. It came into our positive law—the law actually applied by the courts—in 1868 with the Fourteenth Amendment. But what is the grounding for this transformation in our attitudes toward equality under law? Did we need the more radical faith in equality in the sight of God to discover the imperative of treating everyone equally under the law? Is equality under law limited to Americans? If so, why does the Fourteenth Amendment literally protect all “persons” against the American states that deprive them of equal protection of the laws? These are the difficult issues to which we now turn.


The Nation as the Crucible 
of Equality

Gettysburg forged a link between the nation and egalitarian thinking that we sometimes forget. The connection between the limited nation and unbounded equality has paradoxical overtones. The nation is dedicated to the proposition that all men are created equal. The thrust toward equality has universalist implications. Neither Lincoln in 1863 nor the founders in 1776 argued that only “Americans” were created equal. The claim was that all people—in principle, all human beings on the planet—are born with equal dignity. Yet, this universalistic thinking thins our commitment to equality to a point of fragility.
Equality flourishes in an environment of mutual sympathy and reciprocal identification. The love for each and the needs of each come to the fore in the affective bonds of family, friendship, tribe, and, by extension, in the reciprocal attachments of nationhood. The limited political sphere of the nation facilitates the recognition of others as human beings sharing a common history. If blacks and whites, Northerners and Southerners, eventually men and women, could respect each other as Americans participating in the same national drama, they would lay a foundation for affirming their mutual equality. They need not be brothers and not exactly friends, but they could at last recognize each other as compatriots with a common language, a single history, and a shared future.
The source for this association between bonds of affection and equality lies outside the Judeo-Christian tradition, notably in the philosophy of the ancient Greeks. The fullest development comes in Aristotle’s Politics and in the Nicomachean Ethics. The idea of universal human equality was foreign to Aristotle, but he did believe in the mutual recognition of equality within the bonds of friendship and other close associations. Indeed, wishing well for the other as an end in himself is an essential component of philia or friendship understood broadly, and this sentiment, Aristotle believed, provides the necessary foundation for all virtuous behavior.11
Equality appears as a central theme in the virtue of justice as well as friendship. The just person is one who pays due regard to his own interests as well as to those of others. He is able to maintain the proper balance between his own interests and those of others. This is an aspect of distributive justice that generally requires each person to receive a due or proportionate share of the good to be distributed. Aristotle describes this proportion as an expression of geometric equality. Similarly, when one person wrongs another, some correction is necessary. This species of justice is also based on equality, understood arithmetically. The wrongdoer and the victim should both be restored to the state they were in prior to the wrong. This might be done by compelling the wrongdoer to pay compensation from the gains that he has received in order to make up the loss to the victim.
These virtues of friendship and justice require cultivation, for they contribute to the flourishing of the virtuous individual. Adapted to the nationalist argument for equality among all Americans, Aristotle’s argument about friendship would go something like this: we should treat all members of the American polity as equal, with equal concern for their lives, precisely as we would treat friends. By so doing, we as a nation will flourish and we as individuals will flourish from our taking the ends of our compatriots as seriously as we would those of friends.
Each nation must seek equality for the sake of its own flourishing. The sense of common destiny is nowhere better expressed than in the Jewish expression: Kol Jehudim eruvim ze bze [All Jews are responsible for each other]. In the rhetoric of American nationalism, the metaphor of the chosen people, of the substitution of Americans for Jews, recurs as a familiar trope. The sense of organic closeness is implied. The responsibility of the American nation should run to all members of the nation, defined in the Fourteenth Amendment as all those naturalized or born on the soil of the United States and subject to its legal jurisdiction.
Nationalism becomes a virtue if it avoids hatred of outsiders as it encourages mutual respect among insiders. This, indeed, was Lincoln’s ambition in seeking reconciliation in the Gettysburg Address and in his second inaugural address. Accepting his idea of a “new nation dedicated to the proposition that all men are created equal” would have enabled Americans to negotiate the postbellum period without self-seeking and rancor. But this was not, as we saw, the way it happened, particularly after the tragic turn at Ford’s Theatre.
Andrew Johnson’s plan for Reconstruction was plagued by controversies about whether the previously disloyal were still full members of the nation and whether blacks, once emancipated, should ascend a step higher and receive the franchise on equal terms with whites. Lincoln imagined grounding the equality between black and white, Northern and Southern, in a shared sense of nationhood. With the rancorous infighting that dominated Congress in the period 1865 to 1870, the relevance of nationhood began to recede. More important were the ideological issues of loyalty, personal desert, and political self-interest. The question of the black franchise became associated with the fears of Democrats that a coalition of freedmen and Republicans would dominate the postbellum South.
But this should not surprise us. Politics merely occupies the surface of our lives. The give-and-take of daily conflict can lead us easily to forget both our shared purposes and our enduring principles. The Civil War had ushered in a commitment to the equality of all members of the nation. Whatever the struggle for adoption may have been, the language of egalitarian principle came into force. By 1868, we had in place a clause in the Fourteenth Amendment that was unique in American constitutional history: no state could “deprive any person of the equal protection of the laws.” What this clause would imply in practice, no one quite knew. We did know, however, that the legal idea of equality carried no historical gloss. The Constitution had already spoken of “privileges and immunities”12 and the Bill of Rights, of securing “life, liberty, and property” against deprivation “without due process of law.”13 But the Constitution had never before contained the notion of equality of persons before the law.
The remarkable feature of this ideal-bearing language is that it protects all persons within the power of the state—all those whom the state can touch with its legal power. This was hardly a self-evident way for the provision to be drafted. Given the nationalist background of our sentiments of equality, one could readily have formulated the clause: “No state shall deny to any American citizen within its jurisdiction the equal protection of the laws.” That is, because we were bound together foremost as fellow Americans, one would expect a commitment first to the equal treatment of all Americans. The Weimar Constitution in Germany found this to be a perfectly natural way of formulating the commitment to equality: All Germans are equal before the Law.14 It was not until the postwar Basic Law came to be in 1949 that West Germany recognized that a commitment to equality had to be universal. The provision now reads: All human beings are equal before the Law.15 The striking fact is that Americans came to this principle of universalization as early as 1868.
As the distinguished German constitutional law scholar and philosopher of the Weimar period Gerhard Leibholz pointed out, the Western theory of equality has united two distinct strains of thought.16 The first is the Aristotelian principle, which grounds the virtue of equal treatment in the affective bonds of friendship or, by extrapolation, in the ties of nationhood. The Civil War enabled Americans of different cultural strains, some with power, others without, to see themselves as compatriots of a single nation. Their mutual recognition as partners in a common struggle generated a sense that at least they—the Americans—were created equal.
The second great principle in Leibholz’s egalitarian synthesis stressed the universality of all humans in the love of God. This universalization derives from the biblical faith that all persons are created in the image of God.17 The first is limited and circumscribed by the bonds of affective identification. The second breaks the bonds of the nation and extends to persons unknown and unimagined. We will allow ourselves a slight detour to explore these religious ideas and to understand their impact on the theory of equality as it developed under the Fourteenth Amendment.


The Religious Basis 
of Equality

The abolitionist movement began on the heels of the Second Great Awakening of the first three decades of the century. The country overflowed with the religious pursuit of self-perfection, talk of the millennium—the thousand years of peace before the Second Coming of the Lord—and of the hand of God in human affairs. The American revivalists adopted the Jewish idea that our purpose on earth is to complete and perfect God’s creation. As historian William G. McLoughlin sums up the fervor of the times: “The new consensus also included the belief that Americans are a peculiar race, chosen by God to perfect the world.”18
Many of the preachers of the Awakening supported the abolitionist cause but many others did not. Faith in God and the higher law of revelation enables some people to confront the injustice they see around them; it enables others to retreat and to find solace in their personal quest for salvation. Religious beliefs also supported the cause of those who believed in slavery. Lincoln summed up the ambivalent role of religious faith in the Brothers’ War: “Both [sides] read the same Bible, and pray to the same God; and each invokes His aid against the other.”19
Religious faith hardly lays out a straight path leading to the affirmation of human equality. Yet, it is hardly an accident that many of the great abolitionists such as William Lloyd Garrison and Theodore Parker were ministers whose faith fired their dedicated opposition to the great sin of one man’s owning another. These men carried with them an intimate knowledge of the Bible, yet they did not require a consensus of biblical interpretation to support their political commitments. Frederick Douglass argued that slavery was a sin because by “subjecting one man to the arbitrary control of another, it contravenes the first command of the Decalogue. . . .”20 He was appealing to the basic principles of monotheism. But sophisticated biblical exegesis was unnecessary for those who shared the root intuition that slavery was an abomination. Lincoln thought it obviously wrong for men “to ask a just God’s assistance in wringing their bread from the sweat of other men’s faces.”21 These were strong intuitions of evil, tutored by religious faith but obviously not determined by the Bible.
The religious abolitionists had every reason to be drawn to the Declaration of Independence; there they found the religious inspiration for which they could search in vain in the secular monument called the Constitution. “We hold these truths to be self-evident, that all men are created equal.” Behind those created equal stands a Creator—the source as well of our basic human rights, for the text continues by listing the truths we hold to be self-evident: “that they are endowed by their Creator with certain inalienable rights, that among these are life, liberty and the pursuit of happiness.” This noncommittal Deist theme runs through the rhetoric of 1776. God is mentioned only as “nature’s God,” by virtue of which every people is entitled to “a separate and equal station” in the community of nations. This is the basis for the American people’s claiming that no government may rule them without their consent. The end of the Philadelphia Declaration resonates with another invocation of a higher power: “with a firm reliance on the protection of Divine Providence, we mutually pledge to each other our lives, our fortunes and our sacred honor.”
The religious refrain in the charter of our independence differs radically from the flat, secular tone of the 1787 Constitution, which makes no reference to any of the words, “God,” “Creator,” “Providence,” “divine,” or any of their synonyms. The Constitution recognizes no power higher than the will of “We the People.” Yet, the close bond of religious zeal and American politics returns in the Awakening in the early decades of the nineteenth century, a period leading not only to the abolitionist movement but also to the expression of religious passion in foreign policy, particularly in westward expansion under the ideology of manifest destiny.
The invocation of God in the Gettysburg Address is both accidental and entirely predictable. It is accidental in the sense that Lincoln spontaneously added the divine invocation as he neared the end of the address.22 The innovation was predictable. Lincoln’s association of the nation and God derived from his deepest convictions. He thought of Americans as God’s “almost chosen people,” successors to the Jews in a relationship with the Divine that could be described as “almost a covenant.”23 In the mid-nineteenth century, it was relatively easy to believe that we were in the grip of a great historical force, possibly emanating from a higher power. “IN GOD WE TRUST” became a popular motto, appearing for the first time on the nation’s coinage in 1864. Trust in God can generate diverse conclusions, but this does not subtract from the obvious way in which, at the time, faith in God and the Bible nourished the radical claims of human equality.
For modern readers, those who do not think instinctively in the idiom of Genesis and the Psalms, it is worth reviewing the kind of argument for equality found in biblical sources. The central idea that generates the concept of universal humanity or universal brotherhood is that we are made in the image of God. As the story has come down to us from Genesis 1, 26, and 27:

And God said, Let us make man [Adam] in our own image after our likeness, and let them have dominion over the fish of the sea, over the birds of the air, over all the cattle, and over every creeping thing that creeps on the earth. So God created man in his own image, in his own image He created him, male and female He created them.24

There is much to be said about the proper reading of this passage, particularly in relation to the contrary story of creation in Genesis 2, a story that supposedly justifies the subordination of women. The proper reading of the text, as I have argued elsewhere,25 has God creating a single being, both male and female. God gives this being, called Adam, dominion over all the animals but not over the first woman, yet to be created. Only in the later story of the Garden of Eden do we encounter the curse and subordination of Eve. For those who look to the Bible for guidance, therefore, it makes a tremendous difference whether one relies primarily on the egalitarian message in chapter 1, of ultimate human dignity for all, or on chapter 2, with its story leading to the curse of women that they be “ruled by their husbands.”
That creation in the image of God resonated in the culture of the abolitionists is undeniable; the advocates of emancipation readily read into the line “all men are created equal” the vision of creation set forth in Genesis 1. If you believe that an individual is created in the image of God, it is difficult to deny his or her ultimate worth. There is no higher value than God, and therefore partaking of that value confers upon all human beings ultimate human dignity. This point is brought home in the grounding of the prohibition against homicide in Genesis 9:6:

Whoever sheds man’s blood by man shall his blood be shed;
for in the image of God he made Adam. . . .

The infinite dignity of the potential victim generates an absolute ban on killing. The dignity of the victim is as great as any person who might wish to kill him and, therefore, the homicide of an innocent is never justified. This is a remarkable passage for an era in which the killing of the stranger, the “other,” was a routine occurrence.
The basic ideas of Genesis receive their best secular rendition in the moral philosophy of Immanuel Kant, who takes the idea of creation in the image of God and bequeaths to us the idea of universal humanity. We are all essentially alike as members of the human family. We all partake of infinite human dignity:

In the kingdom of ends everything has either value or dignity. Whatever has a value can be replaced by something else which is equivalent; whatever, on the other hand, is above all value, and therefore admits of no equivalent, has a dignity.26

The idea of human dignity, which we now take to be a shared premise of Western civilization, became the backdrop for our current faith in human rights and crimes against humanity.
The Fourteenth Amendment is our placeholder in the evolution of egalitarian thinking. We know very little about how much equality the framers of the amendment intended to secure, and frankly it does not matter. Each generation must struggle to assay how far they are willing to go in the name of egalitarian justice or, by contrast, how far they wish to surrender to the surviving counter-values of hierarchy. In the aftermath of the Civil War it was clear, ironically, that black men were far ahead of white women in ascending the scale of egalitarian possibilities. Black men acquired, at least nominally, both the right to vote and the right to serve on juries. White women and black women alike would acquire neither until well into the twentieth century.
Some might argue that because the United States lagged in recognizing equal legal rights for women, the mood of 1863 would have been hostile to recognizing that women as well as men were equal in the sight of God.27 When Lincoln said, “All men are created equal,” therefore, he meant men—only males were equal in the sight of the Creator. This objection is easily countered. Lincoln explicitly invoked the figures of women in his discourse on human dignity. In 1857, in his speech attacking the Dred Scott decision, Lincoln explicitly refers to the dignity and inherent equality of black women:

In some respects she certainly is not my equal; but in her natural right to eat the bread she earns with her own hands without asking leave of any one else, she is my equal, and the equal of others.28

Even if the textual evidence were silent, however, we would have to interpret “all men are created equal” as inclusive of all human beings—all variations of women, men, and children. This inclusiveness follows from anchoring the great maxim in the idea that human beings were created in the image of God: “So God created man in God’s own image, in the image of God created God it, the first being, male and female God created them.”29 (I recognize that one reading of the biblical text, widely accepted in various religious traditions, holds that God did create a male Adam in his own image and later removed a rib to create Eve.)
Recognizing the inherent moral equality of women in 1863 did not mean, however, that they would receive full legal and political equality as did black men. The notion of “appropriate roles in life” still governed relations among equals and it would take decades for Americans to grasp that the politics of equality can not brook the coercion of women into domestic, apolitical roles, nor could some misguided theory of social organization tolerate the relegation of blacks to a limited number of lower-status professions.
Human Dignity as a 
Placeholder for Equality

One basic value remains curiously absent from those enthroned in the postbellum legal order. The movement to redeem ourselves from the evil of slavery should have prompted a commitment to a value even more basic than equality: the infinite human value of all human beings. In the wake of the Holocaust, the Germans recognized that this was the proper way to initiate the catalogue of basic rights in the 1949 Basic Law (Constitution): “Human dignity is inviolable. All state power is obligated both to protect this value and to respect it.”30 This provision clearly bears the imprint of Kantian moral philosophy, which treats respect for human dignity as an absolute duty of all individuals, including officers of the state.31
The structure of Article I of the German Basic Law bears a striking resemblance to the Thirteenth Amendment, which in its core provides: “Neither slavery nor involuntary servitude shall exist within the United States.” If we think of the prohibition against slavery and involuntary servitude as an affirmation of autonomy, then the passive sentence of the Thirteenth Amendment could be rewritten, without change of content, in the form of the German Basic Law:

Human dignity and autonomy are inviolable. All state power is obligated both to protect and respect autonomy, by eliminating slavery and involuntary servitude.

This would, admittedly, be an unconventional way of formulating the demands of the Thirteenth Amendment. The usual commentary on the amendment stresses simply that it omits the requirement of action by state officials that we find in the Bill of Rights and in the Fourteenth and Fifteenth Amendments. Yet, it is clear that the postbellum order sought to declare a fundamental value as the symbol of the new United States. The motive was similar to the impulse of the German drafters seeking to ground their postwar constitution in the humanistic values of human dignity. There may be intriguing and important differences between human dignity and autonomy, and we shall return to these later. For now, it is important to note merely that the postbellum legal order begins with a commitment of all state power to eliminate the evil that had cursed the United States since its founding.
Significantly, both human dignity and autonomy, both due process and equality, transcend the limits of the nation. It is not only our nationals who are entitled to these basic human rights. All human beings, all persons, should enjoy the same rights—at least so far as they are within the jurisdiction of the state securing those rights. Our commitment to nationhood generates the reciprocal sympathy that enables us to make the move from particular to universal. We may come to understand the meaning of basic rights in the context of the nation but then we are driven to see that all persons, whether members of the nation or not, are entitled to the same treatment.


Alternative Readings

Not everyone agrees that the equality of all persons represents the moral breakthrough of the Fourteenth Amendment. In an alternative version of the postbellum legal order, also based on the value of nationhood, Charles Black stresses the reliance on national citizenship in the first sentence of the Fourteenth Amendment: “All persons born or naturalized in the United States, and subject to the jurisdiction thereof, are citizens of the United States and of the State wherein they reside.” Membership in the nation is now defined by birth on the land, and the fact of nationality, legally recognized as citizenship, generates the most basic right of the new legal order. Black reasons that the amendment places citizenship at the center of the new constitutional order. “No State shall make or enforce any law which shall abridge the privileges or immunities of citizens of the United States.” The centerpiece of the new order, therefore, should have been citizenship and the elaboration of the “privileges and immunities” of citizenship.
The appeal of Black’s reading of the postbellum legal order is that it, too, draws on the Declaration of Independence and the Gettysburg Address. The key phrase in his reading of the Declaration is not the commitment to equality but the clause immediately following: “that they are endowed by their Creator with certain inalienable rights, that among these are life, liberty and the pursuit of happiness.” Black imagines these words coupled with the language of the Ninth Amendment, which implies an unspecified catalogue of rights “retained by the people.” These “inalienable rights” should express themselves in a catalogue of human rights, including the right to sexual privacy, to reproductive freedom, and to governmental services necessary for the “pursuit of happiness.”32 The latter might plausibly encompass education, medical care, a minimal standard of welfare, and perhaps even guaranteed employment.
There is much to be said for Black’s interpretation of the constitutional text. He brings together strands of our legal culture that until his writing seemed to lack internal coherence. He grounds his argument in the familiar rhetoric of rights. He builds his interpretation on critical planks of the postbellum legal order, namely the ideas of nationhood and national citizenship. Yet, the content of his argument reverts back to the language of rights, inalienable rights, rights retained by the people. He invokes the rhetoric we associate with our eighteenth century Constitution enthroning freedom over equality. True, as the title of Black’s book reminds us, Lincoln’s address does rely on one phrase to establish a link with the old legal order: A New Birth of Freedom. Yet, Black ignores the cardinal values of equality and democracy, which, along with nationhood, represent the cornerstones of the postbellum legal order.
Taking the “privileges and immunities” of citizens as the pivotal value of the new order, as Black does, creates its own problems of equality under law. Why should only citizens and not resident aliens enjoy the inalienable rights of “life, liberty and the pursuit of happiness?” Do not immigrants and even undocumented illegals have rights as human beings? The universalist language of the Declaration of Independence hardly dovetails with the parochial category of citizenship in a particular governmental polity. If all men are created equal, if we are endowed by our Creator with certain inalienable rights, it cannot be the case that these rights are limited to those who are classified as the subjects of a particular sovereign.
To be sure, the Reconstruction Amendments had to define citizenship in the United States, at least to heal the divisive scars left by the Dred Scott decision. That infamous act of judicial will, which served only to fuel the passions for war, held that a former slave could never become the citizen of any state. That is why the amendment adds that citizens of the United States are citizens also “of the State wherein they reside.” They could avail themselves, therefore, of a body of law already developed to secure the mutual recognition of the states of “all Privileges and Immunities” of citizens in sister states.33 As history would have it, however, the “privileges and immunities” clause of the Fourteenth Amendment has not had—at least until recently—any impact on constitutional debates.34 The language has lain latent in the text of the Fourteenth Amendment. Whether it will find a suitable purpose in a constitutional scheme built on equality and due process remains to be seen.
Black pursues the theme of freedom and ignores the phrase that in fact requires emphasis in reading Lincoln: a new birth of freedom. The redemption and renaissance of our country would become possible only by confronting our “offences,” and that meant recognizing and compensating for the evil of slavery. The issue that could stimulate a new birth of the nation, therefore, was not freedom itself but freedom tempered by equality before the law.
Yet, there is reason to applaud Black’s reading of our history, as there is to honor the divergent views found in Bruce Ackerman’s and in Akhil Amar’s writings. Ackerman focuses on the de facto transformation of government wrought by the Fourteenth Amendment, enacted by a rump Congress in violation of the express language of the Constitution.35 Amar, too, reads the history in his own way. The postbellum legal order, in his view, shifts our focus from rights that enable us to participate in government to rights that celebrate individual freedom.36 May all these readings flourish. They testify to the innate multiplicity of meanings inherent in the second founding of the United States in the postbellum legal order. Our only problem, then as now, is that we are not sure which way the revolutionary refounding of the nation should go.


The Cusp of Revolution

By 1868 and the enactment of the Fourteenth Amendment, we were perched on the threshold of a constitutional revolution. An entirely new legal order was yearning to work its way clear from the turmoil of the 1860s. The foundation of this new order was painted bold in the phrases that resounded at Gettysburg: nationhood, equality, and democracy. The mechanism for implementing these exhortations would be the new grant of congressional authority in the final clause of the new amendments: “The Congress shall have power to enforce, by appropriate legislation, the provisions of [these articles].” A more powerful central government was a critical part of the new constitutional order. This would be a government that would raise income taxes, as it started to do during the war. This government would enact welfare legislation to care for the widows and orphans of the war. And, most important, it would be a government that would have the capacity to supervise private relationships. The Constitution was no longer focused just on the individual struggling to secure his freedom against the government. The government would have an active role in protecting and securing the autonomy of its citizens. As my rewriting of the Thirteenth Amendment would have it: Securing and protecting the autonomy of labor would become the duty of all state power. Government would have to keep a vigilant watch on all labor transactions to insure that there never again would arise relationships bordering on slavery or involuntary servitude.
In 1866, Congress began to act on its responsibility to guard against the aftershocks of slavery by prohibiting discrimination in all facilities open to the public. African Americans were part of the public, and they should be entitled, as a matter of equality with others, to have access to public transport, theaters, and hotel accommodations. The first Civil Rights Act, therefore, would seek, in the later words of Justice Harlan, to eliminate “the badges of slavery.”37
The commitment, first and foremost, of the new constitutional order was to the equality of all persons affected by the laws of the United States. No one knew how far our collective promise to realize equality in American life would take us. The Fourteenth Amendment could conceivably have been sufficient to insure equal voting rights for all, doing away with the need for the Fifteenth, the Nineteenth, and later amendments to secure the franchise.
With these ideals in place, we have to recognize that the guns of war had stilled very few of our fundamental social conflicts. The rough and tumble of postbellum politics pitted one segment of the nation against the other. The freedmen could aspire to power in the region where they previously had been slaves. Northern carpetbaggers could join forces with Southern scalawags to remake the agricultural South in the image of the industrial North. At stake was the class structure of the South with its landed gentry commanding a servile class of laborers. Behind the political conflicts, however, was a remaking of the American conception of government. And the states would fight by any legal means necessary to realize the position they could not secure with their sacrifices on the battlefields of recent memory.
If war, in the famous saying of Clausewitz, represents a continuation of politics by other means,38 then postbellum legal disputes stood for a continuation of war by other means. All the disputes that eventually led to armed conflict between the states would begin, in the period after 1865, to plague the courts and throw into question the values that the war should have secured. States’ rights, the holding of blacks in a form of servitude called segregation, withholding the franchise from women—all of these would remain central issues for at least another hundred years.
```
Here the screen reaches the end of the document and automatically exits. 

# 2) less -s
When we want to save space and merge multiple blank lines into one, we use this command 

**Example 1**
Here we can see that a lot of blank lines in chapter 9 of Fletcher got merged into 1. From the less display of chapter 9 in the first screen, it is visible that there are no 2 consecutive blank lines.

```
kevindo@Kevins-MacBook-Pro-2 Fletcher % head -n 10 ch1.txt

In recent years, the Secret Constitution has come to assert itself in the opinions, particularly the dissenting opinions, of the Supreme Court. If we are to understand the impact of our implicit postbellum commitment to the ideas of nationhood, democracy, and equality, we cannot limit ourselves to the jurisprudence of the nine justices who happen to sit on the Court in Washington. The Secret Constitution has, in fact, a much deeper grounding in American political and legal culture, and it has come to express itself in diverse arenas. It spontaneously percolates through civil society. It shapes the process of constitutional amendment; indeed, virtually every constitutional amendment enacted since the Civil War expresses, in one way or another, the values of the Secret Constitution. This is true as well of the two leading proposed constitutional amendments that have gained a large political following in the last decade: the proposal to protect the flag against “desecration” and the movement to protect victims of crime. The values of the Secret Constitution have also found their way into subconstitutional federal legislation based, as a technical matter, on the Interstate Commerce Clause, granting Congress authority to regulate commerce “among the states.”1 The earlier defeat in the Supreme Court of the Civil Rights Act of 1866 meant that Congress had to find other means of bringing to bear the same set of values in the pursuit of equal treatment in public facilities and in the workplace. In order to see the resurgence of the three great ideas of the Secret Constitution—nationhood, democracy, and equality—we have to look afield, away from the courts, to these diverse areas that give birth to legal trends and define the bedrock of the American Constitution.2

Constitutional Amendments

Of all the arenas in which the Secret Constitution has come to the fore, none is more impressive than the process of constitutional amendment. All of the amendments adopted and ratified over the last 135 years reveal the traces of a shared understanding, an unconscious plan, of what American government should be like. This is a remarkable thesis, for the general tendency is to assume that the amendments consist in a hodgepodge of special responses to unrelated problems.
The dominant theme is the spread of the franchise and the fine-tuning of the system of democratic representation. But there are other strains from the Secret Constitution as well. As we work our way through the amendments, from the Thirteenth to the Twenty-Seventh, we shall also see a countervailing principle at work. Democracy stresses the responsibility of the people for their self-governance. The offsetting principle is that the government must be strong, well financed, and act with a sense of compassion for the weak and defenseless. Our postbellum commitment to democracy is well known. Less well appreciated is the deep American sense of concern for those who are not able to fend for themselves. The final implication, then, of the Secret Constitution is the commitment of government to the dignity and self-esteem of all its citizens.
If we think of the Civil War as a moral drama, we cannot but perceive a government at work that is committed to the dignity of all. The drama can be narrowly understood as an enormous sacrifice of human life to liberate people held in the most demeaning condition imaginable. The war snuffed out one life, one being created in the image of God, for every seven slaves freed. There might have been a less costly way of solving the problem. Simply waiting and negotiating, we might have seen the market itself render the keeping of slaves too costly an enterprise. Industrialization spreading South might have made “free labor” a more appealing alternative for those who profited from the system of slave labor. The end of plantation capitalism might have come as safely as the demise of communism in Europe. But these possible scenarios are beside the point. The sacrifice did occur. And we thought it was necessary, as Lincoln preached, to cleanse us of our “offences” and to give the nation a “new birth of freedom.” We could not have survived this drama with anything but a sense that government was capable of a great moral undertaking. Government was no longer instituted simply to keep the peace, deliver the mail, and protect us from foreign enemies but also to ensure that we not descend into the kind of evil that seared the soul of the first American Republic. The period of the Civil War witnessed legislative measures that had never been seen before in the United States—the beginning of a national banking system, the issuance of a national currency, a homestead act that distributed 160 acres to each settler, and land grants for building universities. We incorporated this new understanding of government into the Thirteenth Amendment, which declared boldly that the particular kind of evil that had led to war would never again exist in the United States. To prevent this reoccurrence, the federal government would have to be strong and vigilant. It would have to observe the transactions that occurred in the marketplace to ensure that they did not approach the danger zone of “involuntary servitude.” The war itself and this consequent postbellum policy of necessary vigilance laid the foundation for the later expressions of compassion for the weak and defenseless.
From the Thirteenth to the Fifteenth Amendment, however, from 1865 to 1870, we can sense a sharp decline in the moral energy of government. Section 1 of the Fourteenth Amendment contains, of course, the invocations of “privileges and immunities,” “due process,” and “equal protection” that have engaged the Supreme Court and its academic commentators. But implicit in this 1868 amendment is the resurgence of the states’ responsibility for the events that occur within their borders. And Sections 2, 3, and 4 of the amendment contain time-specific provisions designed to penalize the disloyal states and rebel soldiers and officials. These vengeful provisions have caused much mischief, as we have seen, by providing fodder today for those who prefer denying the franchise to convicted felons.3 Still, the equal protection clause was a breakthrough and supplied the anchor for a cardinal principle of the postbellum legal order. And the due process clause would prove to be the umbrella that would enable the Supreme Court, in the last half-century, to develop a jurisprudence of human rights that applies to the entire country.
The framing of the Fifteenth Amendment suffered from the loss of moral ambition. Congress could have drafted the amendment simply to require the franchise for all persons above the age of 21. But that would have required a clear rationale for the democratic franchise, a clear principle telling us who should vote and why. At the most, we had a vague commitment to the new idea of democracy for the entire nation of Americans. The women’s suffrage movement had begun but it had little support. And it was not at all clear that emancipated slaves would receive the vote. Democrats were naturally fearful that the newly enfranchised blacks would vote for the party that promoted their liberation. Republicans in Congress pressed both for the vote for former slaves and for the disenfranchisement of disloyal members of the Confederacy. A new coalition, they hoped, would break the power of the landed élite and bring about a social revolution in the South. President Johnson himself identified with the class of small white farmers in Tennessee, who felt threatened by the potential rise of black political power in the South.
These political considerations played themselves out against ambivalent sentiments about who constituted the “people” in “government of the people, by the people, for the people.” Yet, we should not underappreciate the radical step of granting the franchise to emancipated slaves on the same terms as it was available to the rest of the population. This transformation of a slave population was unique in the history of revolutionary wars. The concept of popular democracy was beginning to take root. We should not forget that despite pretensions of a democratic founding in 1787, the idea that more than a dominant élite should vote was as foreign to the mind of the late eighteenth century as were the terms “American nation” and “equality.” Rule by the demos or the nation was, like equality, still unfolding as a way of life. It had no guiding theory—no rationale and no historical model. It was not at all obvious that the uneducated, propertyless masses should govern the country.
The entire constitutional structure drafted in 1787 needed revamping but, without a compelling theory to guide them, the political powers in Congress settled for the modest demand in the Fifteenth Amendment that the states not deny the franchise “on account of race, color, or previous condition of servitude.” It is hard to imagine a lesser demand on the states, consistent with the policy of treating the emancipated slaves as members of the nation with equal political rights.
The ensuing amendments also pursue the principles latent in the Secret Constitution. The Sixteenth Amendment, ratified after a lapse of forty-five years, recognized the legitimacy of the income tax. The government had already experimented with the income tax during the Civil War, and enacted another tax in the 1890s. The Supreme Court initially upheld the imposition of an income tax,4 but then in 1895, the Court vetoed, five votes to four, the new aspirations of the federal government.5 The rationale for the Court’s intervention was an obscure provision on “direct” and “indirect” taxes in the Constitution of 1787 that had gotten in the way of the new vision of government.6
The Seventeenth Amendment brings us back to the process of developing a democratic system of government. Henceforth, senators would have to be elected not by state legislatures but directly by the people. The tone of the amendment remains deferential to the states’ control of the electoral process, even for national office. The text does not tell us that all people over the age of twenty-one should be entitled to vote but leaves it up to each state to decide who shall be able to vote “for the most numerous branch of the state legislature.” Whatever that standard happens to be will prevail as well for elections to the United States Senate.
The Eighteenth Amendment is the most significant of the lot, for once again we witness in action a government solicitous of the welfare of its people. The structure of this amendment is exactly the same as the Thirteenth. As the latter declares that a certain form of private relationship of subordination shall not exist in the United States, the Eighteenth Amendment tells us, analogously, that another private relationship shall not occur: “the manufacture, sale, or transportation of intoxicating liquors within . . . the United States . . . is hereby prohibited.” This much misunderstood amendment, ratified in 1919, expressed a collective concern for the dignity and welfare of all those whose lives were destroyed by drink. Of course, we know that it did not work, but the sentiment expressed was a noble one. It reflects a politics of mutual responsibility in a single nation, a concern for those who could easily get lost in the rough and tumble of capitalist America.
We encounter this noble motive at work and see its failure in our current policy toward the sale and use of narcotics. We deploy vast sums and personnel in an effort to halt the spread of drug usage, although it is hard to see any tangible payoff from our investment. The reason is simple. It is not easy for government to interdict the pleasures of those who can satisfy them through purely private transactions. The level of vigilance required exceeds the capacity of government in a society that also seeks to protect privacy and civil liberties.
In the case of liquor, in particular, Prohibition had the effect of making consumption tantalizing and exciting. The speak-easy, the drink on the sly, the home brew—all these brought extra pleasure to those who imbibed. The effect of Prohibition was much the same as in the case of flag burning. The law’s forbidding the act makes it more thrilling. The effect is just the opposite of that intended.
Therein lies a message for the politics of governmental intervention. There are times when we must rely on civil society to achieve our goals—sometimes with a slight nudge from government. Witness the turnaround that has occurred in the United States with regard to cigarette smoking. The government posted health warnings on cigarette packs, required airlines and governmental buildings to ban smoking, but did not try to follow the model of Prohibition or the drug laws. The policy of deferring to voluntary initiative has been more effective. A revolution in attitudes toward smoking has occurred, largely because people were free, in effect, to decide for themselves in their homes, offices, and other spheres of influence. They did not need the coercive force of government behind them.
For many, the limitations on governmental power represent a trivial and self-evident proposition. But those who believe in the power of government, as I do, should pay heed. And conservatives, who are generally skeptical of the power of government, would do well to ponder the analogies between Prohibition and the drive for prayer in the schools or the criminalization of flag burning. Of course, there are some areas, such as the protection of the victims of crime, where only the government can act. Of that problem there will be more to say later.
Allow me to take the Twenty-First Amendment out of order. After a decade of Prohibition, the country realized in 1933 that the government simply could not act upon its noble motives. The Constitution had to be amended once more, this time to countermand the Eighteenth Amendment. Some states, for example, Mississippi, retained Prohibition for many more years. As a colleague from ostensibly dry Mississippi once jibed, “Prohibition is better than no liquor at all.” The country as a whole finally decided, however, that a little liquor was more desirable than the costs to freedom in trying to achieve Prohibition.
The rest of the amendments, beginning with the Nineteenth, are all directed to the process of spreading the franchise and refining the mechanism of democratic representation. The Nineteenth (1920), the Twenty-Fourth (1964), and the Twenty-Sixth Amendments (1971) all serve the purpose of extending the franchise. The drafting style follows the Fifteenth Amendment by specifying the criterion on account of which the states may not limit or abridge the right to vote. By using this negative formulation, the first of the series finally extends suffrage to women, the second to those who have not paid a poll tax or any other tax required to vote, and the third, to all men and women over the age of 18. Also in this group is the Twenty-Third Amendment, which extends the right to vote for the president and vice president to citizens otherwise qualified in the District of Columbia.
:
```

**Example 2**
Similarly, here, I used `less -s` command to merge multiple blank lines into 1 in chapter 2 of berk:
```
kevindo@Kevins-MacBook-Pro-2 Fletcher % less -s 20 ch5.txt 




Talia and Jim’s fear of helping 7-year-old Anselmo with his homework, lest they create a dependent, immature child, is a peculiarly Western—and profoundly American—preoccupation. American middle-class parents typically regard young children as dependent beings who must be urged toward independence. In response to researchers’ queries, they frequently say that babies should be trained to be self-reliant from the ﬁrst few months.1 Consequently, they place a high value on children’s learning and doing on their own. Repeatedly relying on others for assistance is construed as weakness, uncertainty, and lack of capacity. In keeping with this view, many American parents worry that if their children seek help, they may become dependent. 
A similar view permeates traditional classrooms, where an individualistic value system prevails. Children must “do their own work.” In the most intensely individualistic of these settings, conferring with your neighbor is worse than dependency; it is cheating, and teachers go so far as to set up barriers between pupils, such as upright books and cardboard screens, to prevent it.
This emphasis on independent accomplishment is not broadly accepted around the world. Indeed, adults in some non-Western cultures regard American parents as rather merciless in pushing their young children toward independence—for example, when they insist that infants sleep alone rather than with their parents, or when they take pleasure in the earliest possible mastery of motor skills, such as crawling and walking, long before the child has acquired the reasoning powers to avoid steep staircases and busy roadways.2
Diverse non-Western peoples and American ethnic minorities stress interdependence—that children must feel intimately linked to others to become competent and self-reliant. Chinese, Japanese, Vietnamese, Guatemalan-Mayan, eastern Kentucky Appalachian, and many other cultural groups regard newborn infants as psychologically separate beings whose most important task is to develop an interdependent relationship with their community—an emotional and social foundation that is crucial for survival and learning.3 Witness the following conclusion by a researcher who compared American with Japanese infant rearing practices: “An American mother–infant relationship consists of two individuals . . . a Japanese mother–infant relationship consists of only one individual, i.e., mother and infant are not divided.”4 These contrasting parenting perspectives reﬂect underlying family and community values. Japanese parents and other ethnic minorities adhere to a collectivist worldview, in which people deﬁne themselves in terms of their relationships with others.
Collectivist values also alter the way teachers and children think about classroom learning. Were you to visit a school on an Israeli kibbutz (cooperative agricultural settlement), you would ﬁnd an explicit emphasis on cooperation and avoidance of pupil comparisons, and a far more positive attitude toward children who seek help than is common in American schools. When asked why children look at each others’ work, kibbutz pupils mention the importance of connecting with others to acquire new skills. They explain, “If your picture looks crooked, you would want to see your friend’s paper to learn how to make it straight,” or “If you aren’t sure what you’re supposed to do, then you should check.” To the same question, American and Israeli urban children typically respond, “I would want to see whose picture was the best,” or “I might be wondering whether she got more right than I did.”5 

from interdependency to autonomy

Vygotsky, who studied and wrote about children’s development in Russia in the early twentieth century, was deeply interested in how interdependency—children’s close ties to their community—can pave the way to competence and autonomy. His sociocultural theory has thoroughly collectivist cultural roots. Vygotsky stressed that children need social interaction and meaningful activities to develop, and he regarded high intrinsic motivation and mature, independent functioning as arising from the support granted by cultural experts as children attempt ever more challenging tasks. The child’s mind, Vygotsky pointed out, “extends beyond the skin” and is inseparably joined with other minds. Out of this interconnection springs mastery, proﬁciency, and self-conﬁdence.6
Nevertheless, a deeply ingrained American belief is that satisfying a young child’s desire for social contact and assistance will be habit forming, leading to a clingy, spoiled youngster. Much evidence veriﬁes that this is not ordinarily so.
Consider the early attachment bond that builds between caregiver and baby during the ﬁrst year of life. By age 6 to 8 months, infants single out their parents and other stable, loving caregivers for expressions of joy and turn to them for comfort when anxious and afraid. An overwhelming consensus of research shows that sensitive caregiving—responding to the baby’s cries for physical care and stimulation promptly, consistently, and appropriately—supports the development of a secure attachment relationship.7 Securely attached infants actively seek contact with and are easily consoled by their familiar, responsive caregiver. Yet such infants are not destined to become immaturely dependent! Rather, by the end of the ﬁrst year, their exploration of the physical world is conﬁdent, persistent, and complex. And they are less likely to cry and more likely to use gestures and words to express their desires than are infants whose parents delayed or failed to respond to their calls for help.8 
Sensitive care builds an interdependent relationship between parent and baby—one in which physical and emotional closeness becomes the context for encouraging more mature behavior. Attachment serves as the springboard for a great many capacities that make their ﬁrst appearance in the second year—self-conﬁdence, compliance and cooperation; awareness of others’ needs and desires, and empathy and sympathy (emotions that enable us to feel for and help others in need).9 But the parent who fails to respond promptly and predictably, intervening only after the baby has become extremely agitated, teaches the infant to rise rapidly to intense distress. The baby has learned that only when he is distraught will the parent reliably come to his aid. As a result, he is more dicult to soothe, to encourage to communicate in ways other than crying, and to guide in acquiring other vital competencies.10
An analogous circumstance exists at older ages, as Anselmo’s interactions with his parents reveal. Jim’s refusal to help Anselmo with his homework, in hopes of instilling independence, is counterproductive. Anselmo’s crying and pleading accelerate, to the point that anxiety prevents him from focusing on the task. Denying Anselmo assistance yields precisely what it was intended to prevent—a dependent, doubting child. As Anselmo’s parents refrain from helping, they fuel his anger and demandingness, and ultimately his sense of helplessness. When Talia ﬁnally responds, she does so out of desperation—to stop Anselmo’s agitated appeals, which are about to escalate beyond control. Consequently, Talia assists inappropriately, by doing the task for him.
Anselmo’s resulting disorganized behavior and dependency prompt additional parental vacillation—sometimes refusals to help, at other times maladaptive helping—along with exasperation and criticism. Talia and Jim can be heard saying impatiently, “You aren’t any good at this!” “Can’t you do anything?”11 Soon a barrier forms between Anselmo and the task he had previously wanted to master, and his motivation wanes.
In classrooms, the same sequence of events prevails. Teachers’ communication plays a vital role in children’s eort and learning. Consider a recent study, in which 1,600 elementary- and middle-school pupils were followed over a 3-year period. Those who viewed their teachers as warm and as providing helpful learning conditions—by making expectations clear and checking that the child understood—worked harder on assignments and participated more in class. Eort and participation, in turn, predicted better academic performance, which sustained the child’s willingness to try hard in the future. In contrast, children who regarded their teachers as unsupportive were more likely to disengage, stop trying, and show declines in achievement. These negative outcomes led children to doubt their own ability, which perpetuated their reduced eort.12
How can adults build interdependent relationships with children that foster the development of culturally meaningful skills and mature, autonomous behavior? To answer this question, Vygotsky proposed a special concept: the zone of proximal development. Keeping it in mind can help parents and teachers interact with children in ways that lead their development forward. 

the zone of proximal development

Take a few moments to list ﬁve or six competencies of a child you know well. If you are a parent, do so for your own child; if you are a teacher, choose a child in your class. Perhaps your list looks much like this one, recorded by Jessica, mother of 3-year-old Tyrone: 

Just learned to cut paper with scissors.
Counts to four.
Looks at picture books and names many pictures.
Remembered two of the animals we saw at the zoo last Sunday. 
Puts together puzzles with eight pieces.
Can sort shapes into categories.
Now indicate whether the skills on your list are ones that the child can do by himself, or whether they are ones that the child displays only when assisted by another person. Jessica, like most parents and teachers completing this exercise, limited her list to Tyrone’s already acquired abilities—ones he can do alone. 
Vygotsky pointed out that we are used to thinking of the child’s capacities in static or “fossilized” terms—as ﬁnished achievements. In doing so, we look toward the past. What we should do, he advised, is to move beyond what children can do by themselves to what they can do with expert assistance and, therefore, have the potential to learn. In this way, we focus on the future—on the cognitive processes of today or tomorrow rather than those of yesterday, which are already mastered.13 
Vygotsky deﬁned the zone of proximal development as the distance between the child’s actual development (the tasks the child can do individually) and the child’s potential development, “determined through problem solving under adult guidance or in collaboration with more capable peers.”14 The “zone,” as I’ll call it from now on, is the dynamic region in which new capacities form as children tackle culturally meaningful tasks with a mentor’s assistance. Had Jessica been thinking about Tyrone’s “zone,” she might have framed the items on her list this way: 

Just learned to cut paper with scissors. If I hold the paper while he cuts and prompt him, he can cut along straight or curved lines. He cut out a square and a circle with help today. I asked him which animals we saw at the zoo, and he mentioned girae and zebra. When I reminded him of the bird and pachyderm houses, he remembered a lot more: the ﬂamingos, parrots, swans, elephants, hippos, and rhinos.

For Vygotsky, a crucial aspect of parenting and the central aim of education is to provide children with experiences in their “zone”—activities that challenge them but that can be accomplished with sensitive adult guidance. Consequently, parents and teachers carry much responsibility for ensuring that children’s learning is maximized—for actively leading them along the developmental pathway. Rather than transmitting ready-made knowledge to a passive child or giving a child tasks for which he or she already has the requisite skills, the adult’s role is to engage in dialogue with the child—by observing, conversing, questioning, assisting, and encouraging. During that dialogue, the adult continually assesses the child’s prch2.txt

```



# 3) less -N

`less -N` is a command that assigns each line in the file a number. 


**Example 1**
In this example, I used `less -N` to assign numbers to lines in chapter 2 of Berk
```
kevindo@Kevins-MacBook-Pro-2 Berk % less -N ch2.txt 




 1
      2 
      3 
      4 
      5 Talia and Jim’s fear of helping 7-year-old Anselmo with his homework, lest they create a dependent, immature child, is a peculiarly Western—and profoundly American—preoccupation. American middle-class parents typically regard young chi      5 ldren as dependent beings who must be urged toward independence. In response to researchers’ queries, they frequently say that babies should be trained to be self-reliant from the ﬁrst few months.1 Consequently, they place a high value      5  on children’s learning and doing on their own. Repeatedly relying on others for assistance is construed as weakness, uncertainty, and lack of capacity. In keeping with this view, many American parents worry that if their children seek      5  help, they may become dependent. 
      6 A similar view permeates traditional classrooms, where an individualistic value system prevails. Children must “do their own work.” In the most intensely individualistic of these settings, conferring with your neighbor is worse than de      6 pendency; it is cheating, and teachers go so far as to set up barriers between pupils, such as upright books and cardboard screens, to prevent it.
      7 This emphasis on independent accomplishment is not broadly accepted around the world. Indeed, adults in some non-Western cultures regard American parents as rather merciless in pushing their young children toward independence—for examp      7 le, when they insist that infants sleep alone rather than with their parents, or when they take pleasure in the earliest possible mastery of motor skills, such as crawling and walking, long before the child has acquired the reasoning p      7 owers to avoid steep staircases and busy roadways.2
      8 Diverse non-Western peoples and American ethnic minorities stress interdependence—that children must feel intimately linked to others to become competent and self-reliant. Chinese, Japanese, Vietnamese, Guatemalan-Mayan, eastern Kentuc      8 ky Appalachian, and many other cultural groups regard newborn infants as psychologically separate beings whose most important task is to develop an interdependent relationship with their community—an emotional and social foundation tha      8 t is crucial for survival and learning.3 Witness the following conclusion by a researcher who compared American with Japanese infant rearing practices: “An American mother–infant relationship consists of two individuals . . . a Japanes      8 e mother–infant relationship consists of only one individual, i.e., mother and infant are not divided.”4 These contrasting parenting perspectives reﬂect underlying family and community values. Japanese parents and other ethnic minoriti      8 es adhere to a collectivist worldview, in which people deﬁne themselves in terms of their relationships with others.
      9 Collectivist values also alter the way teachers and children think about classroom learning. Were you to visit a school on an Israeli kibbutz (cooperative agricultural settlement), you would ﬁnd an explicit emphasis on cooperation and       9 avoidance of pupil comparisons, and a far more positive attitude toward children who seek help than is common in American schools. When asked why children look at each others’ work, kibbutz pupils mention the importance of connecting w      9 ith others to acquire new skills. They explain, “If your picture looks crooked, you would want to see your friend’s paper to learn how to make it straight,” or “If you aren’t sure what you’re supposed to do, then you should check.” To       9 the same question, American and Israeli urban children typically respond, “I would want to see whose picture was the best,” or “I might be wondering whether she got more right than I did.”5 
     10 
     11 
     12 from interdependency to autonomy
     13 
     14 Vygotsky, who studied and wrote about children’s development in Russia in the early twentieth century, was deeply interested in how interdependency—children’s close ties to their community—can pave the way to competence and autonomy. H     14 is sociocultural theory has thoroughly collectivist cultural roots. Vygotsky stressed that children need social interaction and meaningful activities to develop, and he regarded high intrinsic motivation and mature, independent functio     14 ning as arising from the support granted by cultural experts as children attempt ever more challenging tasks. The child’s mind, Vygotsky pointed out, “extends beyond the skin” and is inseparably joined with other minds. Out of this int     14 erconnection springs mastery, proﬁciency, and self-conﬁdence.6
     15 Nevertheless, a deeply ingrained American belief is that satisfying a young child’s desire for social contact and assistance will be habit forming, leading to a clingy, spoiled youngster. Much evidence veriﬁes that this is not ordinari     15 ly so.
     16 Consider the early attachment bond that builds between caregiver and baby during the ﬁrst year of life. By age 6 to 8 months, infants single out their parents and other stable, loving caregivers for expressions of joy and turn to them      16 for comfort when anxious and afraid. An overwhelming consensus of research shows that sensitive caregiving—responding to the baby’s cries for physical care and stimulation promptly, consistently, and appropriately—supports the developm     16 ent of a secure attachment relationship.7 Securely attached infants actively seek contact with and are easily consoled by their familiar, responsive caregiver. Yet such infants are not destined to become immaturely dependent! Rather, b     16 y the end of the ﬁrst year, their exploration of the physical world is conﬁdent, persistent, and complex. And they are less likely to cry and more likely to use gestures and words to express their desires than are infants whose parents     16  delayed or failed to respond to their calls for help.8 
     17 Sensitive care builds an interdependent relationship between parent and baby—one in which physical and emotional closeness becomes the context for encouraging more mature behavior. Attachment serves as the springboard for a great many      17 capacities that make their ﬁrst appearance in the second year—self-conﬁdence, compliance and cooperation; awareness of others’ needs and desires, and empathy and sympathy (emotions that enable us to feel for and help others in need).9      17 But the parent who fails to respond promptly and predictably, intervening only after the baby has become extremely agitated, teaches the infant to rise rapidly to intense distress. The baby has learned that only when he is distraught w     17 ill the parent reliably come to his aid. As a result, he is more dicult to soothe, to encourage to communicate in ways other than crying, and to guide in acquiring other vital competencies.10
     18 An analogous circumstance exists at older ages, as Anselmo’s interactions with his parents reveal. Jim’s refusal to help Anselmo with his homework, in hopes of instilling independence, is counterproductive. Anselmo’s crying and pleadin     18 g accelerate, to the point that anxiety prevents him from focusing on the task. Denying Anselmo assistance yields precisely what it was intended to prevent—a dependent, doubting child. As Anselmo’s parents refrain from helping, they fu     18 el his anger and demandingness, and ultimately his sense of helplessness. When Talia ﬁnally responds, she does so out of desperation—to stop Anselmo’s agitated appeals, which are about to escalate beyond control. Consequently, Talia as     18 sists inappropriately, by doing the task for him.
     19 Anselmo’s resulting disorganized behavior and dependency prompt additional parental vacillation—sometimes refusals to help, at other times maladaptive helping—along with exasperation and criticism. Talia and Jim can be heard saying imp     19 atiently, “You aren’t any good at this!” “Can’t you do anything?”11 Soon a barrier forms between Anselmo and the task he had previously wanted to master, and his motivation wanes.
     20 In classrooms, the same sequence of events prevails. Teachers’ communication plays a vital role in children’s eort and learning. Consider a recent study, in which 1,600 elementary- and middle-school pupils were followed over a 3-year p     20 eriod. Those who viewed their teachers as warm and as providing helpful learning conditions—by making expectations clear and checking that the child understood—worked harder on assignments and participated more in class. Eort and parti     20 cipation, in turn, predicted better academic performance, which sustained the child’s willingness to try hard in the future. In contrast, children who regarded their teachers as unsupportive were more likely to disengage, stop trying,      20 and show declines in achievement. These negative outcomes led children to doubt their own ability, which perpetuated their reduced eort.12
     21 How can adults build interdependent relationships with children that foster the development of culturally meaningful skills and mature, autonomous behavior? To answer this question, Vygotsky proposed a special concept: the zone of prox     21 imal development. Keeping it in mind can help parents and teachers interact with children in ways that lead their development forward. 
     22 
     23 
     24 the zone of proximal development
     25 
     26 Take a few moments to list ﬁve or six competencies of a child you know well. If you are a parent, do so for your own child; if you are a teacher, choose a child in your class. Perhaps your list looks much like this one, recorded by Jes     26 sica, mother of 3-year-old Tyrone: 
     27 
     28 Just learned to cut paper with scissors.
     29 Counts to four.
     30 Looks at picture books and names many pictures.
     31 Remembered two of the animals we saw at the zoo last Sunday. 
     32 Puts together puzzles with eight pieces.
     33 Can sort shapes into categories.
     34 Now indicate whether the skills on your list are ones that the child can do by himself, or whether they are ones that the child displays only when assisted by another person. Jessica, like most parents and teachers completing this exer     34 cise, limited her list to Tyrone’s already acquired abilities—ones he can do alone. 
     35 Vygotsky pointed out that we are used to thinking of the child’s capacities in static or “fossilized” terms—as ﬁnished achievements. In doing so, we look toward the past. What we should do, he advised, is to move beyond what children c     35 an do by themselves to what they can do with expert assistance and, therefore, have the potential to learn. In this way, we focus on the future—on the cognitive processes of today or tomorrow rather than those of yesterday, which are a     35 lready mastered.13 
     36 Vygotsky deﬁned the zone of proximal development as the distance between the child’s actual development (the tasks the child can do individually) and the child’s potential development, “determined through problem solving under adult gu     36 idance or in collaboration with more capable peers.”14 The “zone,” as I’ll call it from now on, is the dynamic region in which new capacities form as children tackle culturally meaningful tasks with a mentor’s assistance. Had Jessica b     36 een thinking about Tyrone’s “zone,” she might have framed the items on her list this way: 

```

**Example 2**
In this example, I also used `less -N` to print out numbered lines in chapter 1 of Berk

```
kevindo@Kevins-MacBook-Pro-2 Berk % less -N ch1.txt



      1 
      2 
      3 
      4 
      5 In my three decades of teaching university courses in child development, I have come to know thousands of students, many of whom were parents or who became parents soon after completing my class. I also served on boards of directors an      5 d advisory committees for child-care centers, preschools, elementary schools, and parent organizations. And my research continually drew me into classrooms, where for countless hours I observed and recorded preschool and school-age chi      5 ldren’s activities, social interactions, and solitary behaviors, in hopes of answering central questions about how they learn.
      6 As a byproduct of those experiences, parents repeatedly approached me with concerns about how to foster their child’s development in the early years. Their fervent questions, at times riddled with doubt and anxiety, revealed that creat      6 ing optimum learning environments for young children at home—and ensuring their access to development-enhancing experiences in child care, preschool, and school—have become mounting parental challenges. 
      7 Consider the following problematic situations that parents recently raised with me:
      8 
      9 •Bob and Sharon, parents of a 4-year-old: Our daughter, Lydia, could recite her ABCs and count from 1 to 20 by age 2 1/2. When we looked for a preschool, many programs appeared to do little more than let children play, so we chose one       9 with lots of emphasis on academics. To me, Lydia’s preschool seems like great preparation for kindergarten and ﬁrst grade, but each morning, Lydia hates to go. Why is Lydia, who’s always been an upbeat, curious child, so unhappy?
     10 •Angela, mother of a 4-year-old and 6-year-old: My husband and I have demanding careers and need to bring work home in the evenings. I’ve read that it’s the quality of time we spend with our children that’s important, not the quantity.     10  We try hard to give Victor and Jeannine our undivided attention, but they’re often whiny, demanding, and quarrelsome. Many times we end up sending them to their rooms or letting them watch TV, just to get some peace after a long day.      10 What’s the best way to create quality parent–child time?
     11 •Talia, mother of a 7-year-old: My son Anselmo, a ﬁrst grader, constantly asks us to help him with his homework. His father ﬁrmly insists that he do it by himself. Anselmo tries, but he gets so frustrated and upset that I move in and h     11 elp, even in the face of opposition from his dad. By that time, Anselmo is on such a short string that I do most of the assignment for him. Should we be helping Anselmo with his homework and, if so, how?
     12 •Noah and Suzanne, parents of a 2-year-old: When our parents were raising us, they seemed conﬁdent of their power and inﬂuence. Recently we read that how children turn out is mostly written in their genes; there’s little we as parents      12 can do about it. Does parenting really matter?rses in child development,     13  I have come to know thousands of students, many of whom were parents or     14  who became parents soon after completing my class. I also served on boa     15 baffled, bewildered parentsry committees for child-care centers, prescho     16 ols, elementary schools, and parent organizations. And my research conti     17 Despite being well educated, intent on doing what’s best for their children, and enlightened by a vast literature of child-rearing advice, many American parents appear uneasy and unsure of their roles at best, baed and bewildered at wo     17 rst. As the above sampling of concerns reveals, today’s parents are not just worried about major transitions and traumas, such as the impact of marital breakup or community violence. They agonize over commonplace, recurrent, everyday s     17 ituations—whether intensive preschool academic tutoring is crucial for later success in school, the meaning of “quality time” with children, and whether and how to help their child with homework. At an even more fundamental level, cont     17 emporary parents have begun to doubt their own ecacy in their children’s development. Why is this so?
     18 The reasons, I believe, are twofold. First, rapid societal changes have complicated parents’ task, making child rearing more challenging than in previous generations. Second, information about child development disseminated to parents      18 is increasingly voluminous but at the same time contradictory. It fails to oer a clear, consistent vision of good child rearing to guide daily decision making and practice. Let’s take a closer look at these sources of parental frustrat     18 ion and confusion.  questions, at times riddled with doubt and anxiety,      19 revealed that creating optimum learning environments for young children      20 Societal Changesring their access to development-enhancing experiences i     21 n child care, preschool, and school—have become mounting parental challe     22 Over the past three decades, external forces impinging on the family have transformed parents’ and, therefore, children’s lives. Overall, parents complain that they have less free time to spend with their children.1 Witness a 1995 surv     22 ey of a large, representative sample of American workers, nearly 25 percent of whom expressed the feeling that the demands of their jobs left them with “no time for family.”2 Compounding their worries, employed parents must, out of nec     22 essity, turn over many hours of child rearing to other adults. Yet once their children are beyond their grasp, they are hardly o the hook! Conscientious parents face an added responsibility: monitoring their child’s whereabouts and act     22 ivities, verifying from a distance that their youngster is physically safe, emotionally contented, and constructively engaged. 
     23 Although many societal conditions heighten parents’ struggle to rear psychologically healthy children, two are especially pernicious, aecting even parents who manage to escape the trials and tribulations of divorce, single parenthood,      23 stepchildren, serious ﬁnancial worries, and other family stresses. The ﬁrst is the dire shortage of acceptable child-care options in the United States, the second is the parental dilemma of “never enough time.” In view of these diculti     23 es, it is little wonder that so many American parents express a sense of powerlessness and inadequacy when it comes to aecting their children’s development. 
     24 
     25 the problem of child care.  In 1970, 30 percent of mothers with pre-school children were in the labor force, a ﬁgure that increased more than twofold, to 62 percent, by 2000.3 An obvious solution to reconciling parents’ employment need     25 s with young children’s rearing needs is to make high-quality, nonparental care, with characteristics known to promote healthy psychological development, widely available and aordable. In Australia and Western Europe, child care is nat     25 ionally regulated and liberally funded to ensure that it conforms to standards veriﬁed by research to foster children’s learning, social competence, and emotional security.4 
     26 Without a nationally regulated and generously subsidized child-care system, formal child care in the United States is in much shorter supply and considerably more costly for parents than it is in other industrialized nations. And as ou     26 r discussion in Chapter 6 will reveal, on the whole, the quality of American child care—whether center-based or home-based—is mediocre to abysmal.5 Indeed, so widespread is poor-quality child care in the United States that Americans ha     26 ve acclimated to it. In a recent survey of parents whose children were enrolled in several hundred randomly chosen child-care centers across four states, over 90 percent believed that their preschoolers’ experiences were far better tha     26 n experts in early childhood development judged those experiences to be.6 Parents seemed unable to distinguish “good” from “substandard” care. 
     27 
     28 the “time bind.”  Like many parents, Angela, who raised the question of quality time, complains of being “torn in many directions.” Often she leaves work in a hurry in the late afternoon to pick up Victor and Jeannine from child care,      28 dashes to Victor’s tumbling class or Jeannine’s piano lesson, then stops at the grocery store to pick up something for dinner. When Angela and her husband, Tom, walk through their front door, they typically head to the phone or fax mac     28 hine to take care of unﬁnished work while trying to quell Victor and Jeannine’s hunger and irritability with a frozen dinner popped into the microwave and unlimited access to the TV set. Caught in a ceaseless sprint to reconcile job, m     28 arriage, and parenting, Angela and Tom feel drained at the end of the day—too tired to grant their children more than 10 or 15 minutes of focused time. When Victor and Jeannine do get their parents’ undivided attention, they are argume     28 ntative and unruly, compounding their parents’ fatigue and impatience. 
     29 Angela and Tom represent a growing number of American parents who try to pencil children into busy schedules, much like a business appointment. They love their children, but they also love and need their work, for personal and ﬁnancial     29  reasons. Hence they ﬁnd themselves in a juggling act between the two, with work usually winning out. Tomorrow will be another day for the kids, they rationalize, but a business deal or a professional achievement, if not capitalized on     29  at the moment, may evaporate. Their logic dovetails with the concept of “quality time” for children. In its commonly accepted meaning, quality time refers to an intense but brief contact. The term is a ready salve for the consciences      29 of conﬂicted parents, who squeeze in a few moments with their children, catch-as-catch-can, yet sense deep down that they are robbing their youngsters—and themselves—of something vital.
     30 The expression “quality time” dates back to the 1970s, a decade that witnessed the largest rise in women’s participation in the labor force during this century. The notion was bolstered by observational studies of parent–child interact     30 ion. In these investigations, some parents exchanged positive emotional signals with and verbally stimulated their infants, and read to and conversed with their preschoolers. Other parents spent time with their children but were not ac     30 tively engaged with them. Time and time again, children of the first set of parents developed more favorably, cognitively and socially, than did children of the second set of parents.7
     31 A close look at the research reveals that children who fared well experienced eective interaction over an extended period. In studies following children from infancy into childhood and adolescence, early brief episodes of parental stim     31 ulation and sensitivity did not result in more competent children.8 Instead, positive, supportive parenting that endured, even when it marked a change from an early period of parental retreat or negative interaction, was linked to favo     31 rable child development, including persistence in problem solving, high self-esteem, socially skilled behavior, closer friendships, and better peer relationships.9 In sum, high-quality involvement with children requires a certain quant     31 ity of time—actually, a great deal, as I’ll argue in this book.
     32 In Angela and Tom’s case, sandwiching concentrated time with Victor and Jeannine between work and other obligations, which often took precedence over family rituals, meant that routines that signal parental caring and that are major so     32 urces of development went by the wayside. For example, family dinnertimes and storybook reading at bedtime became rare events. So did the sheer enjoyment that comes from relaxed parent–child play; a joint cooking, art, or construction      32 project; and a conversation based on real listening and exchange of ideas. Because these experiences were so few and short-lived, Angela and Tom were deprived of valuable opportunities to observe their children closely and to become in     32 timately familiar with their talents, shortcomings, preferences, styles of learning, and ways of coping with hardship—knowledge that is crucial for helping children develop into mature, competent individuals.
     33 Furthermore, the “time bind” stiﬂes an essential child-rearing responsibility that I mentioned earlier and will return to again: monitoring children’s experiences while they are both within and beyond parents’ immediate reach. This inc     33 ludes frequently touching base with nonparental caregivers and teachers to ﬁnd out what’s happening at child care or in the classroom; looking in on sibling and peer interaction to make sure that it is positive and respectful; and cont     33 rolling time spent watching TV and playing video games.
     34 In a recent provocative study, sociologist Arlie Hochschild spent months getting to know employees at a large Midwestern corporation she called Americo. Whether clerical workers or executives, the majority conﬁrmed the parental state o     34 f mind just described: They complained of overly long workdays and frenetic home lives. A surprising ﬁnding, however, was that few Americo workers had taken steps to make work and family more compatible. For example, even well-paid emp:

```
# 4) less -p
`less -p` is a command that	instructs less to start at the first occurrence of the specified pattern in the input file.

**Example 1**
Here I directed the screen to "Talia" in chapter 1 of Berk, and it worked because the screen displays immediately the paragraph that contains "Talia" for me instead of starting from the beginning
```
kevindo@Kevins-MacBook-Pro-2 Berk % less -pTalia ch1.txt




•Talia, mother of a 7-year-old: My son Anselmo, a ﬁrst grader, constantly asks us to help him with his homework. His father ﬁrmly insists that he do it by himself. Anselmo tries, but he gets so frustrated and upset that I move in and help, even in the face of opposition from his dad. By that time, Anselmo is on such a short string that I do most of the assignment for him. Should we be helping Anselmo with his homework and, if so, how?
•Noah and Suzanne, parents of a 2-year-old: When our parents were raising us, they seemed conﬁdent of their power and inﬂuence. Recently we read that how children turn out is mostly written in their genes; there’s little we as parents can do about it. Does parenting really matter?


baffled, bewildered parents

Despite being well educated, intent on doing what’s best for their children, and enlightened by a vast literature of child-rearing advice, many American parents appear uneasy and unsure of their roles at best, baed and bewildered at worst. As the above sampling of concerns reveals, today’s parents are not just worried about major transitions and traumas, such as the impact of marital breakup or community violence. They agonize over commonplace, recurrent, everyday situations—whether intensive preschool academic tutoring is crucial for later success in school, the meaning of “quality time” with children, and whether and how to help their child with homework. At an even more fundamental level, contemporary parents have begun to doubt their own ecacy in their children’s development. Why is this so?
The reasons, I believe, are twofold. First, rapid societal changes have complicated parents’ task, making child rearing more challenging than in previous generations. Second, information about child development disseminated to parents is increasingly voluminous but at the same time contradictory. It fails to oer a clear, consistent vision of good child rearing to guide daily decision making and practice. Let’s take a closer look at these sources of parental frustration and confusion. 

Societal Changes

Over the past three decades, external forces impinging on the family have transformed parents’ and, therefore, children’s lives. Overall, parents complain that they have less free time to spend with their children.1 Witness a 1995 survey of a large, representative sample of American workers, nearly 25 percent of whom expressed the feeling that the demands of their jobs left them with “no time for family.”2 Compounding their worries, employed parents must, out of necessity, turn over many hours of child rearing to other adults. Yet once their children are beyond their grasp, they are hardly o the hook! Conscientious parents face an added responsibility: monitoring their child’s whereabouts and activities, verifying from a distance that their youngster is physically safe, emotionally contented, and constructively engaged. 
Although many societal conditions heighten parents’ struggle to rear psychologically healthy children, two are especially pernicious, aecting even parents who manage to escape the trials and tribulations of divorce, single parenthood, stepchildren, serious ﬁnancial worries, and other family stresses. The ﬁrst is the dire shortage of acceptable child-care options in the United States, the second is the parental dilemma of “never enough time.” In view of these diculties, it is little wonder that so many American parents express a sense of powerlessness and inadequacy when it comes to aecting their children’s development. 

the problem of child care.  In 1970, 30 percent of mothers with pre-school children were in the labor force, a ﬁgure that increased more than twofold, to 62 percent, by 2000.3 An obvious solution to reconciling parents’ employment needs with young children’s rearing needs is to make high-quality, nonparental care, with characteristics known to promote healthy psychological development, widely available and aordable. In Australia and Western Europe, child care is nationally regulated and liberally funded to ensure that it conforms to standards veriﬁed by research to foster children’s learning, social competence, and emotional security.4 
Without a nationally regulated and generously subsidized child-care system, formal child care in the United States is in much shorter supply and considerably more costly for parents than it is in other industrialized nations. And as our discussion in Chapter 6 will reveal, on the whole, the quality of American child care—whether center-based or home-based—is mediocre to abysmal.5 Indeed, so widespread is poor-quality child care in the United States that Americans have acclimated to it. In a recent survey of parents whose children were enrolled in several hundred randomly chosen child-care centers across four states, over 90 percent believed that their preschoolers’ experiences were far better than experts in early childhood development judged those experiences to be.6 Parents seemed unable to distinguish “good” from “substandard” care. 

the “time bind.”  Like many parents, Angela, who raised the question of quality time, complains of being “torn in many directions.” Often she leaves work in a hurry in the late afternoon to pick up Victor and Jeannine from child care, dashes to Victor’s tumbling class or Jeannine’s piano lesson, then stops at the grocery store to pick up something for dinner. When Angela and her husband, Tom, walk through their front door, they typically head to the phone or fax machine to take care of unﬁnished work while trying to quell Victor and Jeannine’s hunger and irritability with a frozen dinner popped into the microwave and unlimited access to the TV set. Caught in a ceaseless sprint to reconcile job, marriage, and parenting, Angela and Tom feel drained at the end of the day—too tired to grant their children more than 10 or 15 minutes of focused time. When Victor and Jeannine do get their parents’ undivided attention, they are argumentative and unruly, compounding their parents’ fatigue and impatience. 
Angela and Tom represent a growing number of American parents who try to pencil children into busy schedules, much like a business appointment. They love their children, but they also love and need their work, for personal and ﬁnancial reasons. Hence they ﬁnd themselves in a juggling act between the two, with work usually winning out. Tomorrow will be another day for the kids, they rationalize, but a business deal or a professional achievement, if not capitalized on at the moment, may evaporate. Their logic dovetails with the concept of “quality time” for children. In its commonly accepted meaning, quality time refers to an intense but brief contact. The term is a ready salve for the consciences of conﬂicted parents, who squeeze in a few moments with their children, catch-as-catch-can, yet sense deep down that they are robbing their youngsters—and themselves—of something vital.
The expression “quality time” dates back to the 1970s, a decade that witnessed the largest rise in women’s participation in the labor force during this century. The notion was bolstered by observational studies of parent–child interaction. In these investigations, some parents exchanged positive emotional signals with and verbally stimulated their infants, and read to and conversed with their preschoolers. Other parents spent time with their children but were not actively engaged with them. Time and time again, children of the first set of parents developed more favorably, cognitively and socially, than did children of the second set of parents.7
A close look at the research reveals that children who fared well experienced eective interaction over an extended period. In studies following children from infancy into childhood and adolescence, early brief episodes of parental stimulation and sensitivity did not result in more competent children.8 Instead, positive, supportive parenting that endured, even when it marked a change from an early period of parental retreat or negative interaction, was linked to favorable child development, including persistence in problem solving, high self-esteem, socially skilled behavior, closer friendships, and better peer relationships.9 In sum, high-quality involvement with children requires a certain quantity of time—actually, a great deal, as I’ll argue in this book.
In Angela and Tom’s case, sandwiching concentrated time with Victor and Jeannine between work and other obligations, which often took precedence over family rituals, meant that routines that signal parental caring and that are major sources of development went by the wayside. For example, family dinnertimes and storybook reading at bedtime became rare events. So did the sheer enjoyment that comes from relaxed parent–child play; a joint cooking, art, or construction project; and a conversation based on real listening and exchange of ideas. Because these experiences were so few and short-lived, Angela and Tom were deprived of valuable opportunities to observe their children closely and to become intimately familiar with their talents, shortcomings, preferences, styles of learning, and ways of coping with hardship—knowledge that is crucial for helping children develop into mature, competent individuals.
Furthermore, the “time bind” stiﬂes an essential child-rearing responsibility that I mentioned earlier and will return to again: monitoring children’s experiences while they are both within and beyond parents’ immediate reach. This includes frequently touching base with nonparental caregivers and teachers to ﬁnd out what’s happening at child care or in the classroom; looking in on sibling and peer interaction to make sure that it is positive and respectful; and controlling time spent watching TV and playing video games.
In a recent provocative study, sociologist Arlie Hochschild spent months getting to know employees at a large Midwestern corporation she called Americo. Whether clerical workers or executives, the majority conﬁrmed the parental state of mind just described: They complained of overly long workdays and frenetic home lives. A surprising ﬁnding, however, was that few Americo workers had taken steps to make work and family more compatible. For example, even well-paid employees were not taking the annual six weeks of federally guaranteed, unpaid family leave time, although they could aord to do so. Nor were they asking for job share or ﬂextime, prominent company policies aimed at increasing the compatibility of work and home. Hochschild concludes, “Many working families are both prisoners and architects of the time bind in which they ﬁnd themselves.”10 
As homes become frenzied places in which work encroaches on family time and parents are too exhausted or preoccupied to be physically and psychologically available, children quickly become discipline problems. Their disagreeable behavior often causes parents to retreat further into the haven of work. On the job, such parents feel competent and gratiﬁed; home has turned into a place where they are harried, annoyed, and must deal with children who sulk, complain, plead for gifts, and are obstinate until they get their way—reactions that cry out, “Fifteen minutes, here or there, with an essentially distracted parent, is not enough.”
Fortunately, not all reports are as disturbing as Hochschild’s. Psychologist Rosalind Barnett and journalist Caryl Rivers conducted extensive interviews with 300 dual-earner couples in the Boston area and found that despite stress at work and at home, most were highly satisﬁed and found child rearing to be both manageable and pleasurable.11 And in a survey of 6,000 employees at DuPont, nearly half—and only slightly more women than men—turned down upward career moves to remain in jobs that allowed for more family commitment.12 Barnett believes that parents most prone to a time bind in which work robs family life are at higher socioeconomic levels—in more pressured jobs that have less clearly deﬁned limits and in which advancement typically depends on superlative performance. Ironically, she notes, economically less well o parents ﬁnd it easier to establish a viable dividing line between workplace and home.13
Although the precise extent of family–work conﬂict in American culture is not clear, its presence and detrimental impact on parent-child interaction and children’s development are well founded. Consider a series of studies that examined length of maternity leave in relation to employed mothers’ psychological well-being and parenting behaviors. Short leaves of 6 weeks or less (the norm in the United States) were linked to maternal anxiety and depression and negative interactions with babies. But longer leaves, of 12 weeks or more, predicted favorable maternal mental health and sensitive, responsive parenting. 14 

```


**Example 2**
Here, I used less -p to direct my screen to the first occurence of "Vygotsky" in chapter 2 of Berk.
```
kevindo@Kevins-MacBook-Pro-2 Berk % less -pVygotsky ch2.txt

Vygotsky, who studied and wrote about children’s development in Russia in the early twentieth century, was deeply interested in how interdependency—children’s close ties to their community—can pave the way to competence and autonomy. His sociocultural theory has thoroughly collectivist cultural roots. Vygotsky stressed that children need social interaction and meaningful activities to develop, and he regarded high intrinsic motivation and mature, independent functioning as arising from the support granted by cultural experts as children attempt ever more challenging tasks. The child’s mind, Vygotsky pointed out, “extends beyond the skin” and is inseparably joined with other minds. Out of this interconnection springs mastery, proﬁciency, and self-conﬁdence.6
Nevertheless, a deeply ingrained American belief is that satisfying a young child’s desire for social contact and assistance will be habit forming, leading to a clingy, spoiled youngster. Much evidence veriﬁes that this is not ordinarily so.
Consider the early attachment bond that builds between caregiver and baby during the ﬁrst year of life. By age 6 to 8 months, infants single out their parents and other stable, loving caregivers for expressions of joy and turn to them for comfort when anxious and afraid. An overwhelming consensus of research shows that sensitive caregiving—responding to the baby’s cries for physical care and stimulation promptly, consistently, and appropriately—supports the development of a secure attachment relationship.7 Securely attached infants actively seek contact with and are easily consoled by their familiar, responsive caregiver. Yet such infants are not destined to become immaturely dependent! Rather, by the end of the ﬁrst year, their exploration of the physical world is conﬁdent, persistent, and complex. And they are less likely to cry and more likely to use gestures and words to express their desires than are infants whose parents delayed or failed to respond to their calls for help.8 
Sensitive care builds an interdependent relationship between parent and baby—one in which physical and emotional closeness becomes the context for encouraging more mature behavior. Attachment serves as the springboard for a great many capacities that make their ﬁrst appearance in the second year—self-conﬁdence, compliance and cooperation; awareness of others’ needs and desires, and empathy and sympathy (emotions that enable us to feel for and help others in need).9 But the parent who fails to respond promptly and predictably, intervening only after the baby has become extremely agitated, teaches the infant to rise rapidly to intense distress. The baby has learned that only when he is distraught will the parent reliably come to his aid. As a result, he is more dicult to soothe, to encourage to communicate in ways other than crying, and to guide in acquiring other vital competencies.10
An analogous circumstance exists at older ages, as Anselmo’s interactions with his parents reveal. Jim’s refusal to help Anselmo with his homework, in hopes of instilling independence, is counterproductive. Anselmo’s crying and pleading accelerate, to the point that anxiety prevents him from focusing on the task. Denying Anselmo assistance yields precisely what it was intended to prevent—a dependent, doubting child. As Anselmo’s parents refrain from helping, they fuel his anger and demandingness, and ultimately his sense of helplessness. When Talia ﬁnally responds, she does so out of desperation—to stop Anselmo’s agitated appeals, which are about to escalate beyond control. Consequently, Talia assists inappropriately, by doing the task for him.
Anselmo’s resulting disorganized behavior and dependency prompt additional parental vacillation—sometimes refusals to help, at other times maladaptive helping—along with exasperation and criticism. Talia and Jim can be heard saying impatiently, “You aren’t any good at this!” “Can’t you do anything?”11 Soon a barrier forms between Anselmo and the task he had previously wanted to master, and his motivation wanes.
In classrooms, the same sequence of events prevails. Teachers’ communication plays a vital role in children’s eort and learning. Consider a recent study, in which 1,600 elementary- and middle-school pupils were followed over a 3-year period. Those who viewed their teachers as warm and as providing helpful learning conditions—by making expectations clear and checking that the child understood—worked harder on assignments and participated more in class. Eort and participation, in turn, predicted better academic performance, which sustained the child’s willingness to try hard in the future. In contrast, children who regarded their teachers as unsupportive were more likely to disengage, stop trying, and show declines in achievement. These negative outcomes led children to doubt their own ability, which perpetuated their reduced eort.12
How can adults build interdependent relationships with children that foster the development of culturally meaningful skills and mature, autonomous behavior? To answer this question, Vygotsky proposed a special concept: the zone of proximal development. Keeping it in mind can help parents and teachers interact with children in ways that lead their development forward. 


the zone of proximal development

Take a few moments to list ﬁve or six competencies of a child you know well. If you are a parent, do so for your own child; if you are a teacher, choose a child in your class. Perhaps your list looks much like this one, recorded by Jessica, mother of 3-year-old Tyrone: 

Just learned to cut paper with scissors.
Counts to four.
Looks at picture books and names many pictures.
Remembered two of the animals we saw at the zoo last Sunday. 
Puts together puzzles with eight pieces.
Can sort shapes into categories.
Now indicate whether the skills on your list are ones that the child can do by himself, or whether they are ones that the child displays only when assisted by another person. Jessica, like most parents and teachers completing this exercise, limited her list to Tyrone’s already acquired abilities—ones he can do alone. 
Vygotsky pointed out that we are used to thinking of the child’s capacities in static or “fossilized” terms—as ﬁnished achievements. In doing so, we look toward the past. What we should do, he advised, is to move beyond what children can do by themselves to what they can do with expert assistance and, therefore, have the potential to learn. In this way, we focus on the future—on the cognitive processes of today or tomorrow rather than those of yesterday, which are already mastered.13 
Vygotsky deﬁned the zone of proximal development as the distance between the child’s actual development (the tasks the child can do individually) and the child’s potential development, “determined through problem solving under adult guidance or in collaboration with more capable peers.”14 The “zone,” as I’ll call it from now on, is the dynamic region in which new capacities form as children tackle culturally meaningful tasks with a mentor’s assistance. Had Jessica been thinking about Tyrone’s “zone,” she might have framed the items on her list this way: 

Just learned to cut paper with scissors. If I hold the paper while he cuts and prompt him, he can cut along straight or curved lines. He cut out a square and a circle with help today. I asked him which animals we saw at the zoo, and he mentioned girae and zebra. When I reminded him of the bird and pachyderm houses, he remembered a lot more: the ﬂamingos, parrots, swans, elephants, hippos, and rhinos.

For Vygotsky, a crucial aspect of parenting and the central aim of education is to provide children with experiences in their “zone”—activities that challenge them but that can be accomplished with sensitive adult guidance. Consequently, parents and teachers carry much responsibility for ensuring that children’s learning is maximized—for actively leading them along the developmental pathway. Rather than transmitting ready-made knowledge to a passive child or giving a child tasks for which he or she already has the requisite skills, the adult’s role is to engage in dialogue with the child—by observing, conversing, questioning, assisting, and encouraging. During that dialogue, the adult continually assesses the child’s progress and creates the “zone” by keeping the task “proximal”—slightly above the child’s level of independent functioning. In this way, the adult “rouses to life” those cognitive processes that are just emerging in the child,15 sustaining them socially so they can be reﬁned and internalized as part of the child’s psychological world.


creating the “zone”

What features of adult–child shared activity forge the “zone”? Research documents several communicative ingredients that consistently foster development, in children of diverse ages and across a wide range of tasks.

Shared Understanding

For information, ideas, and skills to move from the social-interactive plane to the internal-thinking plane, the adult and child must strive for a common approach to the situation. They must desire genuine communication and work toward attaining it. 
In sociocultural theory, this joint, mutual focus is called intersubjectivity, or shared understanding.16 As the word suggests, each participant in the dialogue strives to grasp the subjective perspective of the other, an eort that results in a “meeting of minds,” in which the partners’ thoughts make contact, connect, and coincide. Intersubjectivity reaches its pinnacle in a love aair, where shared understanding is readily achieved through a glance, a touch, or a comment. Lovers in close psychological contact grasp one another’s meanings quickly because each is on the lookout for and tries to satisfy the other’s needs.17 The opposite of intersubjectivity is total misunderstanding. In a failed love aair, widely divergent views of the same experiences cause people to say, “You don’t understand me. You’ve become a stranger. We can’t ﬁnd common ground. We’ve grown apart.”
The image of lovers communicating helps us appreciate the circumstances in which intersubjectivity is most likely to occur: in close relationships. Children most often attain it with parents, other family members, teachers, and eventually in fch2.txt

```




